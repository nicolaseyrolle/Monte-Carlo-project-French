{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Méthodes de Monte Carlo: Projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"microbenchmark\")\n",
    "install.packages(\"plot3D\")\n",
    "install.packages(\"matlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'microbenchmark' was built under R version 3.6.2\"Warning message:\n",
      "\"package 'plot3D' was built under R version 3.6.2\"Warning message:\n",
      "\"package 'matlib' was built under R version 3.6.2\""
     ]
    }
   ],
   "source": [
    "library(\"microbenchmark\")\n",
    "library(\"plot3D\")\n",
    "library(\"matlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partie I - Simulations de variables aléatoires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)\n",
    "\n",
    "Générer des réalisations d'une variable aléatoire selon une uniforme de support  $[0,1]$ nécéssite d'utiliser la méthode de la fonction inverse. Ici, la loi de Gumble est continue de densité\n",
    "$$ f(x)=\\frac{1}{\\beta}\\exp(\\exp(-\\frac{x-\\mu}{\\beta}))\\exp(-\\frac{x-\\mu}{\\beta})$$ avec $\\mu\\in\\mathbb{R}$ et $\\beta\\in \\mathbb{R}_{+}^{*}$.\n",
    "Elle est munie de la fonction de répartition suivante: $$F(x)=\\exp(\\exp(-\\frac{x-\\mu}{\\beta}))$$\n",
    "\n",
    "\n",
    "La méthode de la fonction inverse consiste à calculer la fonction inverse $F^{\\leftarrow}(u):=\\ inf\\{t\\in\\mathbb{R},\\ F(t)\\geq u \\}$  avec $u\\in\\left[0,1\\right]$. puis de l'évaluer par $U \\sim U[0,1]$. La méthode garantit que résultat de notre évaluation suit bien la loi de $\\mathbf{X}$. \n",
    "\n",
    "Dans notre cas , la loi de Gumbel est continue on a donc $F^{\\leftarrow}=F^{-1}$.\n",
    "\n",
    "Un calcul rapide nous donne:\n",
    "\n",
    "\\begin{align}\n",
    "F(x)&=y\\\\\n",
    "\\Leftrightarrow  \\exp(-\\exp(-\\frac{x-\\mu}{\\beta}))&=y\\\\\n",
    "\\Leftrightarrow -\\frac{x-\\mu}{\\beta}&=ln(-ln(y))\\\\\n",
    "\\Leftrightarrow  x=\\mu-\\beta ln(-ln(y))&=F^{-1}(y)\\\\\n",
    "\\end{align}\n",
    "\n",
    "Voici le code de simulation de variables aléatoires i.i.d suivant la loi de Gumbel(1,2) d'après la méthode décrite ci-dessus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "simGumbel = function(m, a, b){\n",
    "  u = runif(m, 0, 1)        #on simule n uniformes\n",
    "  Fi = -b*log(-log(u))+a    #on évalue les uniformes par la fonction inverse\n",
    "  return(Fi)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### b)\n",
    "\n",
    "Pour nous convaincre du résultat de la méthode de la fonction inverse nous allons user de plusieurs outils de comparaisons:\n",
    "\n",
    "* L'histogramme de l'échantillon simulé\n",
    "* La fonction de répartitions empirique de notre échantillon\n",
    "* Le test de Kolmogorov-Smirnov\n",
    "\n",
    "Une discussion sur la pertinence de ces différents outils s'impose:\n",
    "Les deux premiers ont pour avantage de donner des représentations graphiques et nous permettent ainsi de nous donner une première idée du caractère Gumbélien de notre échantillon. \n",
    "\n",
    "En effet, si l'histogramme et notre fonction de répartition empiriques sont très différents de leurs homologues théoriques alors on peut conclure hâtivement que notre échantillon ne suit pas une loi de Gumbel. Toutefois, si les graphes des deux premiers outils de comparaison semblent similaires voire identiques on ne peut conclure sur le caractère Gumbélien de notre échantillon.\n",
    "\n",
    "L'idéal serait de pouvoir quantifier notre confiance dans l'acceptation de cette hypothèse. D'où l'importance d'utiliser le test de  Kolomogorov-Smirnov. La p-value que nous renvoie ce dernier nous permet de quantifier la certitude de nos premiers résultats. \n",
    "\n",
    "Nous détaillons ci-dessous les codes des trois méthodes susmentionnées:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nYII=",
      "text/plain": [
       "Plot with title \"Histogramme de X\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Comparaison de de l'histogramme de notre échantillon avec la densité f (ici pgumbel)\n",
    "\n",
    "dgumbel = function(x, a = 1, b = 2){\n",
    "  return((1/b)*exp(-exp(-(x-a)/b))*exp(-(x-a)/b))  # calcul de la densité d'une Gumbel de paramètres a,b ici fixés.\n",
    "}\n",
    "\n",
    "Fi = simGumbel(m=1000, a=1, b=2) #Échantillon de 1000 Gumbels\n",
    "\n",
    "hist(Fi, freq  =  FALSE, main= \"Histogramme de X\", xlab= \"X\")   #Trace l'histogramme des valeurs\n",
    "\n",
    "curve(dgumbel(x, a=1, b=2), -5, 15, add = T)   #Superpose la densité avec l'histogramme\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que notre histogramme s'ajuste très bien à notre densité. Il n'y a aucune raison à ce stade de rejeter l'hypothèse, bian au contraire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAABNTU1oaGh8fHyM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\nAAAAAElFTkSuQmCC",
      "text/plain": [
       "Plot with title \" Comparaison des Fonctions de répartition\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Comparaison de la fonction de répartion empirique de notre échantillon avec celle d'une loi Gumbel:\n",
    "\n",
    "pgumbel = function(x, a = 1, b = 2){\n",
    "  return(exp(-exp(-(x-a)/b)))         #calcul de la fonction de repartition d'une Gumbel\n",
    "}\n",
    "X = simGumbel(m=1000, a=1, b=2)    #simule un echantillon de taille 1000\n",
    "plot(ecdf(X), main = \" Comparaison des Fonctions de répartition\")         # Trace fonction de repartition empirique\n",
    "curve(pgumbel(x, a=1, b=2), add = TRUE, col = 2)# Trace la fonction de répartition d'une Gumbel et la superpose avec la fonction de répartition empirique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Analyse des résultats:\n",
    "\n",
    "1. Dans le premier graphique, on remarque que l'histogramme de notre échantillon s'ajuste idéalement avec notre densité.\n",
    "\n",
    "\n",
    "2. Même conclusion pour le graphique concernant la fonction de repartition empirique qui semble se confondre avec la fonction de repartition d'un loi de Gumbel(1,2).\n",
    "\n",
    "\n",
    "3. Les premiers tests paraissent de bonne augure dans l'acceptation de l'Hypothèse que notre échantillon suit une loi de Gumbel. Néanmoins le test de Kolmogorov-Smirnov nous permettra de précisier notre confiance à l'aide de la p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tOne-sample Kolmogorov-Smirnov test\n",
       "\n",
       "data:  X\n",
       "D = 0.02284, p-value = 0.6739\n",
       "alternative hypothesis: two-sided\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### On teste nos hypothèses avec un test ( Kolmogorov-Smirnov)\n",
    "\n",
    "X = simGumbel(m=1000, a=1, b=2) #Échantillon de taille 1000\n",
    "ks.test(X, \"pgumbel\",  a=1,  b=2) #Éxecution du test de Kolmogorv-Smirnov de niveau 95 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Synthèse:\n",
    "\n",
    "1. La p-valeur retournée par le test de Kolmogorv-Smirnov est bien supérieure à 0,05. On ne rejette donc pas l'hypothèse que notre échantillon suit une loi de Gumbel. La grande différence qui existe entre la p-valeur et notre niveau de rejet nous donne une grande confiance dans la croyance que notre échantillon suit bien une loi de Gumbel(1,2).\n",
    "\n",
    "\n",
    "2. D'après l'étude de notre échantillon à l'aide des différents outils de comparaison, on accepte, sans grand risque, que l'échantillon simulé d'après la méthode de la fonction inverse suit bien une loi de Gumbel(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) \n",
    "Soient $\\mathbf{X}_{(1)}=\\max(\\mathbf{X}_1,...,\\mathbf{X}_n)$ et $\\mathbf{X}_{(m)}=\\min(\\mathbf{X}_1,...,\\mathbf{X}_m)$.\n",
    "Pour calculer la densité de la loi jointe $(\\mathbf{X}_{(1)},\\mathbf{X}_{(m)})$ nous allons calculer les dérivées croisées de la fonction de répartition jointe.\n",
    "Pour le calcul de la fonction de répartition il y a deux cas:\n",
    "Soit $(x,y)\\in\\mathbb{R}^2$\n",
    "\n",
    "\n",
    "* si $x \\leq y$, on a:\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "F_{\\mathbf{X}_{(1)},\\mathbf{X}_{(m)}}(x,y)&=\\mathbb{P}(\\mathbf{X}_{(1)}\\leq x , \\mathbf{X}_{(m)}\\leq y)\\\\\n",
    "&=\\mathbb{P}(\\mathbf{X}_{(m)}\\leq y)-\\mathbb{P}(x \\leq \\mathbf{X}_{(1)}\\ ,\\ \\mathbf{X}_{(m)}\\leq y)\\\\\n",
    "&=\\mathbb{P}({\\bigcap}_{i=0}^m \\mathbf{X}_{i}\\leq y)-\\mathbb{P}(x \\leq {\\bigcap}_{i=0}^m \\mathbf{X}_{i}\\leq y)\\\\\n",
    "&=F(x)^m-(F(x)-F(y))^m \\text{ avec  F  fonction de répartition d'une Gumbel(1,2)}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "* si $y < x$, on a:\n",
    "\n",
    "\n",
    "Cela signifie que $\\mathbf{X}_{(m)} < \\mathbf{X}_{(1)}$.\n",
    "Ce qui est impossible d'où $F_{\\mathbf{X}_{(1)},\\mathbf{X}_{(m)}}(\\mathbf{X},y)=0$\n",
    "\n",
    "\n",
    "En définitive on obtient:\n",
    "$$ F_{\\mathbf{X}_{(1)},\\mathbf{X}_{(m)}}(x,y) = F(x)^{m}-(F(x)-F(y))^{m}\\mathbb{1}_{\\{x \\leq y\\}} $$\n",
    "\n",
    "\n",
    "En effectuant les dérivées croisées de $F$ on obtient:\n",
    "\n",
    "$$ \\frac{\\partial F(x,y)}{\\partial x \\partial y}=m(m-1)(F(x)-F(y))^{m-2}f_\\mathbf{X}(x)f_{\\mathbf{Y}}(y)\\mathbb{1}_{\\{x\\leq y\\}}=f_{1,m}(x,y) $$\n",
    "\n",
    "où $f_\\mathbf{X}(x)$ et $f_Y(y)$ sont les densités de respectivement de $\\mathbf{X}$ et $\\mathbf{Y}$, indépdendantes et suivant une loi de Gumbel(1,2).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b)\n",
    "$F_{X_{(1)},X_{(m)}}:\\mathbb{R}^2 \\rightarrow \\mathbb{R}$ n'est pas inversible. \n",
    "Nous ne disposons donc pas des hypothèses nécéssaires pour appliquer la méthode de la fonction inverse pour simuler un échantillon selon $f_{1,m}$. \n",
    "\n",
    "\n",
    "De plus, on remarque que  \n",
    "$$(F(x)-F(y))^{m-2}\\mathbb{1}_{\\{x\\leq y\\}}\\leq 1$$\n",
    "D'où, $$f_{1,n}(x,y)\\leq m(m-1)g(x,y)$$\n",
    "\n",
    "avec $g = f_{\\mathbf{X}}f_{\\mathbf{Y}}$ la densité jointe de $({\\mathbf{X}},{\\mathbf{Y}})$ couple de v.a  i.i.d suivant suivant la loi de Gumble(1,2). \n",
    " \n",
    "Étant donné cette majoration on peut appliquer l'algorithme d'acceptation-rejet.\n",
    "Le principe de la méthode est d'effectuer des réalisations $z_i$ selon la lois $g$ qui vérifie $f_{1,n}\\leq m(m-1)g$. À partir de ces la réalisations on génére des v.a uniformes conditionnellement aux  réalisations $z_i$ telles que $(\\mathbf{U}|\\mathbf{Z}=z_i)_i \\sim \\mathbf{U}\\left[0,1\\right]$. Le critère d'acceptation de nos réalisations est le suivant :on ne garde que les réalisations des uniformes qui se trouvent sous la courbe de . Ces dernières sont bel et bien des réalisations selon $$f_{1,n)$$ .\n",
    "Une telle méthode garantit une probabilité d'acceptation égale à $\\frac{1}{m(m-1)}$. Il nous faudra donc en moyenne $n*m(m-1)$ réalisations pour obtenir un échantillons  de taille n simulés selon la loi du couple $(\\mathbf{X}_{(1)},\\mathbf{X}_{(m)})$ .\n",
    "\n",
    "\n",
    "Voici le code de l'algorithme d'acceptation-rejet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ARminmaxGumbel = function(nb_pairs, m, a=1, b=2){\n",
    "  cte  =  m*(m-1)                        #constante de majoration\n",
    "  nb_trials  =  ceiling(nb_pairs * cte)  #Nombre d'essais moyen pour obtenir le nombre de paire souhaité sachant que la proba d'accepter est de 1/m(m-1).\n",
    "  \n",
    "  #on génére un couple selon la densite jointe f*f\n",
    "  y1  =  simGumbel(nb_trials, a, b)\n",
    "  y2  =  simGumbel(nb_trials, a, b)\n",
    "  \n",
    "  u  =  runif(nb_trials,  0, cte*dgumbel(y1, a, b)*dgumbel(y2, a, b)) # simulations de nb_trials Uniforme sur [0,cte*dgumbel(y1, a, b)*dgumbel(y2, a, b)]\n",
    "  \n",
    "  indicatrice =  ifelse(y1<y2,  1,  0)\n",
    "  f1m_y  =  indicatrice*m*(m-1)*dgumbel(y1, a, b)*dgumbel(y2, a, b)*(pgumbel(y2, a, b)-pgumbel(y1, a, b))**(m-2) #densité du couple\n",
    "  x1 = y1[ u < f1m_y ]       #critère d'acceptation\n",
    "  x2 = y2[ u < f1m_y ]       #idem\n",
    "  \n",
    "#Étant donné que l'on fait une approximation du nombre de simulation nécssaires pour obtenir nb_pairs ,on complète notre échantillon pour qu'il soit de la taille souhaitée\n",
    "\n",
    "    if (length(x1) >=  nb_pairs ){\n",
    "    x1  =  x1 [1:nb_pairs]         #si le nombre de v.a simulé est plus grande que la taille n attendue on conserve les n premières v.a\n",
    "    x2  =  x2 [1:nb_pairs]         #idem\n",
    "  }else {                       #si ce n'est pas le cas: on complète. On applique la méthode d'acceptation rejet pour une seule simulation jusqu'à ce qu'on obtienne le nombre souhaité\n",
    "    n_reste  = nb_pairs-length(x1)\n",
    "    \n",
    "    for (i in 1:n_reste) {\n",
    "      y1  =  simGumbel(1, a, b)\n",
    "      y2  =  simGumbel(1, a, b)\n",
    "      u  =  runif(1,  0, cte*dgumbel(y1, a, b)*dgumbel(y2, a, b))\n",
    "      \n",
    "      indicatrice =  ifelse(y1<y2,  1,  0)\n",
    "      f1m_y  =  indicatrice*m*(m-1)*dgumbel(y1, a, b)*dgumbel(y2, a, b)*\n",
    "                    (pgumbel(y2, a, b)-pgumbel(y1, a, b))**(m-2)\n",
    "      \n",
    "      while ( u>=   f1m_y){\n",
    "        \n",
    "        y1  =  simGumbel(1, a, b)\n",
    "        y2  =  simGumbel(1, a, b)\n",
    "        u  =  runif(1,  0, cte*dgumbel(y1, a, b)*dgumbel(y2, a, b))\n",
    "        \n",
    "        indicatrice =  ifelse(y1<y2,  1,  0)\n",
    "        f1m_y  =  indicatrice*m*(m-1)*dgumbel(y1, a, b)*dgumbel(y2, a, b)*\n",
    "                  (pgumbel(y2, a, b)-pgumbel(y1, a, b))**(m-2)\n",
    "        \n",
    "      }\n",
    "      x1  = append(x1,  y1)  # On ajoute un à un toute les v.a qui vérifient le critère d'acceptation\n",
    "      x2  = append(x2,  y2)  #idem\n",
    "    }\n",
    "  }\n",
    "  return(matrix(c(x1, x2), ncol  = 2))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Commentaires \n",
    "1. Nos ordinateurs peinent à retourner l'échantillon souhaité pour $m=100$ et $n=100$ en utilisant ARminmaxGumbel. Cette difficulté s'explique au regard de de la probabilité d'accepter qui est de $\\frac{1}{9900}$. Ainsi pour simuler 100 paires de $((X_{(1)}^{i},X_{(m)}^{i}))_{i\\geq1}$ il faut simuler en moyenne $990000$ Gumbel(1,2) ce qui est énorme !!! Nous limiterons donc notre étude à $n=100$ et $m=10$ en raison du manque de puissance de nos ordinateurs. Ce résultat nous montre à quel point il est important de ne pas avoir une constante majoration trop brutale de la densité dans le cas général.\n",
    "\n",
    "\n",
    "2. La remarque précédente nous pousse à réflechir à une nouvelle méthode de simulation. Pour réaliser 100 simulations de $((X_{(1)},X_{(100)}))_{i\\geq1}$ On peut penser à simuler $n$ échantillons de taille $m=100$ suivant une Gumbel(1,2) puis d'en extraire le minimum et le maximum. Dans cette méthode on a donc $n*m=100*100=10000$ de simulations de Gumbel(1,2) à réaliser. Ce qui est presque 100 fois plus efficace que l'algorithme d'acceptation rejet.\n",
    "En voici le code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"temps d'éxécution minmaxGumbel 1351400\"\n",
      "[1] \"temps d'éxécution minmaxGumbel 42884062\"\n",
      "[1] \"temps relative d'éxécution: 0.0315128730109568\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "minmaxGumbel = function(nb_pairs, m , a =1, b = 2){\n",
    "    Min_vect = c() #créer un vecteur prêt à stocker les valeurs du min\n",
    "    Max_vect = c() #idem pour le max\n",
    "    \n",
    "    # On simule nb_pairs*m gumbel , pour ensuite les ségmenter par échantillon de taille m dans une matrice\n",
    "    Z = simGumbel(nb_pairs*m, a, b)  \n",
    "    M= matrix(Z,nrow=nb_pairs,byrow=TRUE)\n",
    "    \n",
    "    # On stock nos résultats dans les vecteurs crées plus haut\n",
    "    Min_vect= apply(M,1,FUN=min)\n",
    "    Max_vect= apply(M,1,FUN=max)\n",
    "    \n",
    " return(matrix(c(Min_vect, Max_vect), ncol  = 2))\n",
    "}\n",
    "\n",
    "eff1= mean(microbenchmark(minmaxGumbel(nb_pairs=100, m=10, a=1, b=2))$time)\n",
    "print(paste0(\"temps d'éxécution minmaxGumbel \",eff1))\n",
    "\n",
    "eff= mean(microbenchmark(ARminmaxGumbel(nb_pairs=100, m=10, a=1, b=2))$time)\n",
    "print(paste0(\"temps d'éxécution minmaxGumbel \",eff))\n",
    "print(paste0(\"temps relative d'éxécution: \" ,eff1/eff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Commentaires:\n",
    "\n",
    "\n",
    "1. Le ratio produit par la fonction ci-dessus se réecrit de la forme suivante $\\frac{temps\\ d'éxecution\\ algorihtme\\ minmaxGumbel}{temps\\ d'éxecution\\ algorihtme\\ ARminmaxGumbel}$ Ainsi plus  ce ratio est proche est petit par rapport à 1, plus le temps d'éxecution de ARminmaxGumbel est long face à celui de minmaxGumbel.  En particulier, dans notre cas pour $nb_{pairs}=100$ et $m=10$ est de l'odre de $10^{-2}$. Ainsi, ce ratio permet de confirmer notre intuition de départ: Pour simuler un échantillon de $((X_{(1)},X_{(10)}))_{i\\geq1}$ minmaxGumbel est presque 100 fois plus rapide que ARminmaxGumbel.\n",
    "\n",
    "\n",
    "\n",
    "2. Bien que minmaxGumbel soit plus performant que ARminmaxGumbel, il faut relativiser son efficacité. En effet il est important de garder à l'esprit que pour simuler un échantillon de taille n de réalisations de $(X_{(1)},X_{(m)})$ minmaxGumbel nécéssite de simuler $n*m$ Gumbels. Dans notre cas 9900 simulations sont ignorées( bien qu'elles fassent partie du processus de simulation de notre couple de v.a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vérification de ARminmaxGumbel:\n",
    "\n",
    "Estimer les échantillons selon minmaxGumbel nous permet d'avoir une distribution précise. C'est pourquoi afin de voir si ARminmaxGumbel simule bien selon la loi demandée nous allons effectuer des comparaisons avec les réalisations de minmaxGumbel.\n",
    "\n",
    "Pour ce faire, nous allons tracer l'histogramme 3D de nos distributions pour les comparer. Après divers éssais (et quelques plantages) nous avons remaqué que les histogrammes convergent lentement l'un vers l'autre. Nous avons donc choisi de simuler 10000 échanillons de taille 5 pour limiter le temps de calcul et obtenir des graphes relatviement significatifs.\n",
    "\n",
    "Par ailleurs, nous effectuerons un test de Kolmogorov-Smirnov sur une estimations de $\\Delta=\\mathbf{X}_{(n)}-\\mathbf{X}_{(1)}$( qui sera notre variable d'intrêt dans la seconde partie) selon nos deux méthodes. Bien entendu cette dernière démarche ne donne aucune information sur la loi du couple. Néanmoins, si le résultat du test réfute l'hypothèse selon laquelle $\\Delta$ simulé avec les deux différents algorithmes possèdent la même loi alors on pourra affirmer que ARminmaxGumbel ne fonctionne pas correctement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAABMlBMVEUAAAAAAI8AAJgAAKEA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\niASAAv8PO/J0PGHyJ9MAAAAASUVORK5CYII=",
      "text/plain": [
       "Plot with title \"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####Comparaison graphique des échantillons simulés (minmaxGumbel vs ARminmaxGumbel):\n",
    "\n",
    "alea=200\n",
    "#  On simule les données selon minmaxGumbel\n",
    "set.seed(alea) #fixe l'aléa \n",
    "x1 <- minmaxGumbel(nb_pairs=10000,m=5,a=1,b=2)[,1]\n",
    "y1 <- minmaxGumbel(nb_pairs=10000,m=5,a=1,b=2)[,2]\n",
    "\n",
    "#  Calcul le nombre d'apparition de chaque valeur prise par le min et le max\n",
    "x_c1 <- cut(x1, 20)\n",
    "y_c1 <- cut(y1, 20)\n",
    "\n",
    "#  Fusionne nos deux cuts et permet donc d'avoir le nombres d'apparitions du couple \n",
    "z1 <- table(x_c1, y_c1)\n",
    "\n",
    "\n",
    "#  On simule les données selon ARminmaxGumbel\n",
    "set.seed(alea) #fixe l'aléa\n",
    "x2 <- ARminmaxGumbel(nb_pairs=10000,m=5,a=1,b=2)[,1]\n",
    "y2 <- ARminmaxGumbel(nb_pairs=10000,m=5,a=1,b=2)[,2]\n",
    "\n",
    "#  Calcul le nombre d'apparition de chaque valeur prise par le min et le max\n",
    "x_c2 <- cut(x2, 20)\n",
    "y_c2 <- cut(y2, 20)\n",
    "\n",
    "#  Fusionne nos deux cuts et permet donc d'avoir le nombres d'apparitions du couple \n",
    "z2 <- table(x_c2, y_c2)\n",
    "\n",
    "# Créer une matrice de taille 2x2 dans laquelle figurera\n",
    "par(mfrow=c(2,2)) \n",
    "\n",
    "## Plot as a 3D histogram\n",
    "hist3D(z=z1, border=\"black\")\n",
    "\n",
    "hist3D(z=z2, border=\"black\")\n",
    "\n",
    "##  Plot as a 2D heatmap:\n",
    "image2D(z=z1, border=\"black\")\n",
    "\n",
    "image2D(z=z2, border=\"black\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tTwo-sample Kolmogorov-Smirnov test\n",
       "\n",
       "data:  delta1 and delta2\n",
       "D = 0.17, p-value = 0.1111\n",
       "alternative hypothesis: two-sided\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####Test de kolomogorv smirnov pour delta:\n",
    "\n",
    "# Simulation des échantillons selon les deux algorithmes\n",
    "x=minmaxGumbel(nb_pairs=100,m=10,a=1,b=2)\n",
    "y=ARminmaxGumbel(nb_pairs=100,m=10,a=1,b=2)\n",
    "\n",
    "#Calcul de delta pour chaque échantillons\n",
    "delta1=x[,2]-x[,1]\n",
    "delta2=y[,2]-y[,1]\n",
    "\n",
    "#test de Komlogorov-Smirnov\n",
    "ks.test(delta1,delta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse:\n",
    "\n",
    "Les histogrammes sont relativement proches l'un de l'autre. Malheureusement la puissance de nos ordinateurs ne nous permet pas de pouvoir augmenter la taille de notre échantillon pour effectuer une étude plus précise... Bien que cela ne soit pas suffisant pour affirmer que les lois simulées soient identiques et donc que ARminmax soit une bonne méthode de simulation, nous ne sommes pas non plus en mesure de réfuter cette hypothèse. De plus la p value du test de Kolomogorov est très supérieure à 0.05. Cela signifie que l'algorithme de rejet peut être utilisé dans la partie suivante vouée à l'étude de $\\delta=\\mathbb{E}\\left[\\Delta\\right]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partie II - Estimation de l'étendue par la méthode de Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a)\n",
    "  On cherche à obtenir une estimation de $\\delta=\\mathbb{E}[X]$ avec un précision de $\\epsilon=10^{-2}$ au niveau de confiance $95 \\%$. \n",
    "On s'attachera à donner un intervalle de confiance centré en $\\delta$ à l'aide à l'aide de l'estimateur de Monte Carlo $\\hat{\\Delta}_{n}$ défini comme suit: $$\\hat{\\Delta}_n=\\frac{1}{n}\\sum_{i=1}^{n}(X^{i}_{(m)}-X^{i}_{(1)})$$ pour tout couple $((X^{i}_{(1)},X^{i}_{(m)}))_{i\\geq 1}$ i.i.d.\n",
    "\n",
    "Regardons les propriétés de $\\hat{\\Delta}_{n}$:\n",
    "1. $\\hat{\\Delta}_{n}$ est trivialement non biasé par linéarité de l'espérance. \n",
    "2. $\\hat{\\Delta}_{n}$ est fortement consistant. En effet, on a:\n",
    "\\begin{align*}\n",
    "X_{(m)}^2 &\\leq (max_{1\\leq i\\leq n}(|X_i|))^2\\\\\n",
    "&\\leq (\\sum_{i=1}^n |X_i|)^2\\\\\n",
    "&\\leq (\\sum_{i=1}^n |X_i|^2)\\ d'après\\ l'inégalité\\ de\\ Jensen\n",
    "\\end{align*} \n",
    "\n",
    "Il s'agit d'une somme finie de variables suivant une loi de Gumbel(1,2) et appartiennent donc à $L^2$. Ainsi $X_{(m)}$ (et $\\mathbf{X}_{(1)}$ par raisonnement symétrique) possède ont un moment d'ordre 2 fini. En vertu de l'inégalité de Cauchy-Schwartz on a: $$\\mathbb{E}\\left[|X_{(1)}|\\right] \\leq \\mathbb{E}\\left[|X_{(1)}|^2\\right]\\mathbb{P}(\\Omega) < +\\infty$$. Idem pour $X_{(n)}$.\n",
    "\n",
    "Ainsi $X_{(1)}$ et $X_{(n)}$ sont dans $\\mathcal{L}^1$ . On en déduite que $\\Delta \\in \\mathcal(L)^1$. Comme somme de deux variable $\\mathcal{L}^1$. On conclut par l'utilisation de la loi des grands nombres.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Plusieurs méthodes peuvent nous permettent d'aboutir à un intervalle de confiance vérifiant ce résultat. \n",
    "Nous nous attacherons à utiliser deux d'entre elles:\n",
    "\n",
    "1. L'inégalité de Bienaymé-Tchebitchev\n",
    "    * a) Utilisation d'une majoration théorique de la variance\n",
    "    * b) Estimation de la variance par méthode de chauffe\n",
    "    \n",
    "\n",
    "2. Théorème Centrale Limite \n",
    "    * Estimation de la variance par méthode de chauffe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Inégalité de Tchebytchev:\n",
    "###### Majoration théorique\n",
    "\n",
    "Nous rappelons que $\\hat{\\Delta}_n$ est un estimateur trivialement non biaisé appliquée à $((X^{i}_{(m)}-X^{i}_{(1)}))_{i\\geq 1}$\n",
    "\n",
    "D'après l'inégalite de Bienaymé-Tchebytchev on a:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb{P}(|\\hat{\\Delta}_n-\\delta|\\geq \\epsilon) \\leq var(\\hat{\\Delta}_n)=\\frac{\\sigma^2(\\hat{\\Delta}_n)}{n}=\\frac{\\sigma^2(\\Delta)}{n\\epsilon^2}\n",
    "\\end{align*}\n",
    "\n",
    "L'objectif est de trouver la taille de l'échantillon $n$ telle que la probabilité pour $\\delta$ d'être en dehors de l'intervalle $[\\hat{\\Delta}-\\epsilon,\\hat{\\Delta}+\\epsilon]$ soit  inférieure à $5 \\% $.\n",
    "On souhaite donc calculer\n",
    "\n",
    "\\begin{align}n\\in \\mathbb{N},\\ \\mathbb{P}(|\\hat{\\Delta}_n-\\delta|\\geq \\epsilon) \\leq 0,05\n",
    "\\end{align}\n",
    "\n",
    "   Étant donné que l'on ne connait pas $var(\\Delta)$ on va majorer la variance de $\\Delta$.\n",
    "\n",
    "Premièrement, on a:\n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma^2(\\Delta)&=\\mathbb{E}[\\Delta^2] -\\mathbb{E}[\\Delta]^2\\\\\n",
    "&\\leq \\mathbb{E}[\\Delta^2] \\ \\ \\ \\ \\ car\\ \\mathbb{E}[\\Delta]^2 \\geq 0 \\\\\n",
    "&= \\mathbb{E}[X_{(1)}^2]+\\mathbb{E}[X_{(m)}^2]-2\\mathbb{E}[X_{(m)} X_{(1)}] \\\\\n",
    "\\end{align*}\n",
    "\n",
    "De plus, on remarque que:\n",
    "\n",
    "1. $\\mathbb{E}[X_{(1)}^2]$ se calcule selon la loi marginale de $X_{(1)}$ de densité:\n",
    "$$f_1(x)= \\frac{\\partial F(x,y)}{\\partial x}=mF(x)^{m-1}f_X(x)\\leq mf_X(x)$$. Ainsi on a : $\\mathbb{E}[X_{(1)}^2]\\leq m\\mathbb{E}[X^2]$ avec X qui suit une loi de Gumbel(1,2).\n",
    "Symétriquement on a $\\mathbb{E}[X_{(m)}^2]\\leq m\\mathbb{E}[Y^2]$ avec X et Y i.i.d .\n",
    "\n",
    "\n",
    "\n",
    "2. On a montré plus haut que $X_{(1)}$ et $ X_{(n)}$ sont dans $L^2$.\n",
    "\n",
    "\n",
    "On peut donc appliquer l'inégalité de Cauchy-Schwartz. On obtient:\n",
    "$$ -2\\mathbb{E}[X_{(m)} X_{(1)}] \\leq (\\mathbb{E}[X_{(1)}^2]\\mathbb{E}[X_{(m)}^2])^{\\frac{1}{2}}$$\n",
    "\n",
    "\n",
    "D'où:\n",
    "\n",
    "\\begin{align*}\n",
    "\\sigma^2(\\Delta) &\\leq \\mathbb{E}[X_{(1)}^2]+\\mathbb{E}[X_{(m)}^2]-2\\mathbb{E}[X_{(m)} X_{(1)}]\\\\\n",
    "&\\leq n\\mathbb{E}[X^2]+n\\mathbb{E}[Y^2]+n\\mathbb{E}[X^2]^{\\frac{1}{2}}\\mathbb{E}[Y^2]^{\\frac{1}{2}}\\\\\n",
    "&\\leq 2m(var(X)+\\mathbb{E}[X]^2)\\ \\ \\ car\\ X,Y\\ i.i.d \\\\\n",
    "&= 2m(\\frac{4pi^2}{6} + (1+2\\gamma)^2)\\\\\n",
    "&= 2mC \\ \\ avec\\ C=\\frac{4pi^2}{6} + (1+2\\gamma)^2\n",
    "\\end{align*} \n",
    "\n",
    "\n",
    "Finalement, on obtient: \n",
    "\n",
    "$$\\mathbb{P}(|\\hat{\\Delta}_n-\\delta|\\geq \\epsilon) \\leq \\frac{2mC}{n\\epsilon^2}$$\n",
    "\n",
    "On en déduit la valeur de $n$, pour $m=100=10^{2}$\n",
    "$$ \\frac{2*10^{6}C}{n}= 5*10^{-2} \\Leftrightarrow n= 4*10^{7}*C$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Nombre de simulation nécéssaires pour obtenir une précision de epsilon: 382265385.224803\"\n"
     ]
    }
   ],
   "source": [
    "##### CODE qui renvoie les bornes de notre intervalles de confiances d'après la méthode de Bienaymé Tchebytchev.\n",
    "\n",
    "Estim_delta_Tchebychev_minmax = function(m, a = 1, b = 2, eps = 10*{-2}){\n",
    "  \n",
    "    nb_realisations = 4*10^{7}*(pi^{2}*(3/4)+a+b*(-digamma(1))) # calcul du nombre de réalisations nécéssaire pour obtenir la précision demandée\n",
    "    x = minmaxGumbel(nb_pairs=nb_realisations, m, a, b)  # On simule nb_pairs Gumbel(a,b)\n",
    "    \n",
    "    delta = mean(x[,2]-x[,1])             # calcul de l'estimateur de Monte-Carlo\n",
    "    var=var(x)                           #Calcul de la variance de delta\n",
    "    \n",
    "    inf = mean-eps                       #borne inf de l'intervalle de confiance\n",
    "    sup = mean+eps                       #borne sup de l'intervalle de confiance\n",
    "  return(c(nb_pairs, inf, sup, delta, var))  #retourne un vecteur v=(borne inf, borne sup, nombre d'itérations, estimateur, variance de l'estimateur) \n",
    "}\n",
    "\n",
    "nb_realisations= 4*10^{7}*(pi^{2}*(3/4)+1+2*(-digamma(1)))\n",
    "print(paste0(\"Nombre de simulation nécéssaires pour obtenir une précision de epsilon: \",nb_realisations))\n",
    "\n",
    "# Code identi au précédent à la différence que l'on simule selon ARminmaxGumbel et non plus minmaxGumbel\n",
    "Estim_delta_Tchebychev_ARminmax = function(m= 100, a = 1, b = 2, eps = 10*{-2}){\n",
    "  nb_pairs = 4*10^{7}*(pi^{2}*(3/4)+a+b*(-digamma(1)))\n",
    "  x = minmaxGumbel(nb_pairs, n, a, b)\n",
    "  mean = mean(x[,2]-x[,1])\n",
    "  var=var(x)\n",
    "  inf = mean-eps\n",
    "  sup = mean+eps\n",
    "  return(c(inf, sup,nb_pair,mean,var))\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Commentaires et Utilisation d'une \"chauffe\" pour limiter le nombre de simulation nécéssaires pour parvenir à la précision demandée (méthode empirique)\n",
    "\n",
    "\n",
    "Le nombre de simulations nécéssaire pour obtenir une estimation de précision $\\epsilon$ est de l'ordre de 300 millions. le nombre de simulation élevé provient des majorations brutales successives  que l'on a eu à effectuer pour trouver n. En raison de ce nombre de simulation, il nous est impossible de calculer l'éfficacité relative des estimateurs pour une précision de $\\epsilon$.\n",
    "\n",
    "\n",
    "Ainsi, plutot que de majorer, essayons d'obtenir une estimation de $\\sigma^2(\\Delta)$  à l'aide d'une \"période de chauffe\". Soit $\\hat{\\sigma}$.\n",
    "D'après l'inégalité de Bienaymé Tchebytchev on a alors:\n",
    "\n",
    "$$\\mathbb{P}(|\\hat{\\Delta}_n-\\delta|\\geq \\epsilon) \\leq \\frac{\\hat{\\sigma}}{n\\epsilon^2}$$\n",
    "\n",
    "\n",
    "Le nombre de simulation nécéssaire pour avoir une précision d'ordre $\\epsilon$ pour un niveau de confiance $95\\%$ est de :\n",
    "\n",
    "$$\\frac{\\hat{\\sigma}}{n\\epsilon^2}=0,05 \\Leftrightarrow \\frac{\\hat{\\sigma}}{0,05\\epsilon^2}=n \\Leftrightarrow \\frac{10^6\\hat{\\sigma}}{5}=n \\Leftrightarrow 2*10^5\\hat{\\sigma}=n$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Nombre de simulation nécessaires pour obtenir une précision de epsilon: 1316701.46118059\"\n",
      "[1] \"Variance estimée pour ce n: 6.58350730590293\"\n"
     ]
    }
   ],
   "source": [
    "nombre_de_realisations_tchebytchev=function(nb_pairs_de_ref, m, eps , a, b){\n",
    "    \n",
    "    x  =   minmaxGumbel(nb_pairs_de_ref, m, a, b)   # Simulation de (nb_pairs_de_ref) gumbel\n",
    "    \n",
    "    delta  =  x[,2]-x[,1]                          # Calcul de delta\n",
    "\n",
    "    var_estim =  var(delta)                         # approximation de la variance de delta\n",
    "    \n",
    "    q=qnorm(0.975,0,1)                              # retourne le quantile de niveau 97.5 % de la loi normale centrée réduite\n",
    "    nb_realisations  =  var_estim/(eps^{2} * 0.05)  # Calcul du nombre de réalisations nécéssaires pour obtenir une precision de epsilon\n",
    "    \n",
    "    return(c(nb_realisations, var_estim))\n",
    "}\n",
    "\n",
    "algo_tchebytchev=nombre_de_realisations_tchebytchev(nb_pairs_de_ref=3000, m=100, eps = 10^{-2}, a=1, b=2)\n",
    "nb_realisations = algo_tchebytchev[1]\n",
    "var_estim= algo_tchebytchev[2]\n",
    "\n",
    "print(paste0(\"Nombre de simulation nécessaires pour obtenir une précision de epsilon: \",nb_realisations))\n",
    "print(paste0(\"Variance estimée pour ce n: \", var_estim))\n",
    "\n",
    "\n",
    "estim_delta_tchebychev_minmax = function(nb_pairs_de_ref, m, eps = 10^{-2}, a = 1, b = 2 ){\n",
    "  nb_pairs = nombre_de_realisations_tchebytchev(nb_pairs_de_ref, m, eps , a, b)\n",
    "  x = minmaxGumbel(nb_pairs, m, a, b)[1]\n",
    "  delta_hat = mean(x[,2]-x[,1])\n",
    "  var=var(x)\n",
    "  inf = mean-eps\n",
    "  sup = mean+eps\n",
    "  return(c(nb_pairs, delta_hat, var, inf, sup))\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Commentaires:\n",
    "\n",
    "À l'aide du code ci-dessus on observe que pour un nombre de chauffe de 3000, $\\hat{\\sigma}\\simeq6$ on obtient donc $n\\simeq1.2*10^6$.\n",
    "En comparaison avec l'algorithme fondé sur l'inégalité de Bienaymé Tchebychev qui nécéssite un nombre de simulations de gumbel de l'ordre des centaines de millions, la méthode de chauffe nous permet d'économiser un facteur 100 de simulation ce qui est non négligeable.\n",
    "Toute fois cela ne reste pas suffisant pour estimer $\\delta$ en vue du niveau de puissance nos ordinateurs.\n",
    "\n",
    "\n",
    "En effet, comme nous l'avons vu dans la première partie, simuler 10000 gumbel avait déjà un certain coût. Le million de simulation s'avère donc difficilement éxecutable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Intervalle de confiance asymptotique\n",
    "\n",
    "##### Méthode expérimentale dite de \"chauffe\"\n",
    "\n",
    "$\\hat{\\Delta}_n$ est dans $\\mathcal{L}^2$ et consistant. En particulier on peut appliquer le théorème centrale limite et ainsi obtenir un intervalle de confiance asymptotique de niveau $95\\%$ pour n suffisemment grand.\n",
    "\n",
    "On a donc \n",
    "$$IC^{1-\\alpha}_n=[\\hat{\\Delta}_n-q_{1-\\alpha}\\sqrt{\\frac{\\sigma^2(\\Delta)}{n}},\\hat{\\Delta}_n+q_{1-\\alpha}\\sqrt{\\frac{\\sigma^2(\\Delta)}{n}}]$$ avec $q_{1-\\alpha}$ le quantile de niveau $1-\\alpha$ de la loi $\\mathcal{N}(0,1)$\n",
    "\n",
    "Cet intervale a un niveau de précision $\\epsilon$ ssi:\n",
    "\n",
    "\\begin{align*}\n",
    "diam(IC^{1-\\alpha}_n)&=\\epsilon\\\\\n",
    "\\Leftrightarrow 2 q_{1-\\alpha}\\sqrt{\\frac{\\sigma^2(\\Delta)}{n}}&=\\epsilon\\\\\n",
    "\\Leftrightarrow 4 q_{1-\\alpha}^2{\\frac{\\sigma^2(\\Delta)}{\\epsilon^2}}&=n\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Tout comme nous l'avons fait pour Bienaymé-Tchebychev, nous allons donner une \"période de chauffe\" pour estimer $\\sigma^2$ puis à partir de cet estimation nous obtiendrons le n demandé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Variance estimée pour le nombre de chauffe choisi 6.58350730590293\"\n",
      "[1] \"Nombre de simulation nécessaires pour obtenir une précision de epsilon: 1068686.88485119\"\n"
     ]
    }
   ],
   "source": [
    "nombre_de_realisation_ICA=function(nb_pairs_de_ref, m, eps, a, b){\n",
    "    \n",
    "    nb_pairs_de_ref = 3000  #initialisation du nombre de chauffe\n",
    "    x  =   minmaxGumbel(nb_pairs_de_ref, m, a, b)# simulation selon le nombre de chauffe de Gumbel\n",
    "    \n",
    "    delta  =  x[, 2]-x[, 1] # calcul de delta\n",
    "    \n",
    "    var_estim =  var(delta) #estimation de la variance pour ce nombre de chauffe\n",
    "    \n",
    "    q=qnorm(0.975,0,1)\n",
    "    nb_realisations = 4*(q^2 )*var_estim/eps^{2} # calcul du nombre  de réalisation nécessaires pour obtenir une precision de epsilon\n",
    "    \n",
    " return(nb_realisations)\n",
    "}\n",
    "\n",
    "nb_realisations=nombre_de_realisation_ICA(nb_pairs_de_ref = 3000,m=100,eps = 10^{-2},a=1,b=2)\n",
    "\n",
    "\n",
    "\n",
    "print(paste0(\"Variance estimée pour le nombre de chauffe choisi \", var_estim))\n",
    "print(paste0(\"Nombre de simulation nécessaires pour obtenir une précision de epsilon: \",nb_realisations))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étant donné le nombre de simulations demandées pour obtenir une estimation est de l'ordre de $nb_{pairs}=10^6$.\n",
    "Comme chaque algorithme nécéssite la simulation de $nb_{pairs}$ $(X_{(1)}^{i},X_{(n)}^{i})$ selon minmaxGumbel ou ARminmax, il nous est impossible de calculer la variance relative des deux estimeurs.( Ce n'est pas faute d'avoir essayé, l'ordinateur a planté à plusieurs reprises). Nous donnons néanmois ci-dessous, une trace de code qui pourrait nous servir à une estimation d'un nombre plus petit de Gumbel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICA_asymptotique_minmaxGumbel=function(m, nb_pairs, a, b){\n",
    "    \n",
    "    #simulations du nb_pairs de minmax gumbel, ici nb_pairs= nb_réalisations, pour obtenir une precision de epsilon avec \n",
    "    x = minmaxGumbel(nb_pairs, m, a, b)\n",
    "    \n",
    "    #calcul de delta et de son estimateurs\n",
    "    delta =  x[, 2]-x[, 1]\n",
    "    delta_hat = mean(delta)\n",
    "    \n",
    "    #calcul de la variance de delta pour nb_pairs simulations\n",
    "    sigma2 = var(delta)\n",
    "    \n",
    "    #Calcul des bornes de l'intervalle de confiance\n",
    "    q=pnorm(0.975,0,1)\n",
    "    inf = delta_hat - (q^2 )*sqrt(sigma2/nb_pairs)\n",
    "    sup = delta_hat + (q^2 )*sqrt(sigma2/nb_pairs)\n",
    "    \n",
    "    return(c(delta_hat, sigma2, inf, sup))   \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Code identique à ICA_asymptotique_minmaxGumbel sauf que l'on simule selon ARminmaxGumbel\n",
    "\n",
    "ICA_asymptotique_ARminmaxGumbel=function(m, nb_pairs, a, b){\n",
    "    x  =   ARminmaxGumbel(nb_pairs, m, a, b)\n",
    "    \n",
    "    delta =  x[, 2]-x[, 1]\n",
    "    delta_hat = mean(delta)\n",
    "    \n",
    "    var= var(delta)\n",
    "    q=pnorm(0.975,0,1)\n",
    "    \n",
    "    inf = delta_hat - (q^2 )*sqrt(sigma2/nb_pairs)\n",
    "    sup = delta_hat + (q^2 )*sqrt(sigma2/nb_pairs)\n",
    "    \n",
    "    return(c(delta_hat, sigma2, inf, sup))   \n",
    "}\n",
    "\n",
    "# en principe il faudrait éxécuter les commandes suivantes pour obtenir l'intervalle de confiance, la valeur de notre estimateurs et sa variance\n",
    "# Nous ne le faisons pas du fait du manque de puissance de nos ordinateurs:\n",
    "\n",
    "#ICA_minmax = ICA_asymptotique_minmaxGumbel(nb_pairs=nb_realisations,m=100,a=1,b=2)\n",
    "#delta_hat_minmax = ICA_minmax[1]\n",
    "#sigma2_minmax = ICA_minmax[2]\n",
    "#inf_minmax = ICA_minmax[3]\n",
    "#sup_minmax= ICA_minmax[4]\n",
    "#print(paste0(\"Valeur estimateur minmax \", delta_hat_minmax))\n",
    "#print(paste0(\"Variance estimateur Score a: \",sigma2_minmax))\n",
    "#print(paste0(\"Intervalle de confiance Score a: [\",inf_minmax,\",\",sup_minmax,\"]\"))\n",
    "\n",
    "#ICA_ARminmax = ICA_asymptotique_ARminmaxGumbel(nb_pairs=nb_realisations,m=100,a=1,b=2)\n",
    "#delta_hat_ARminmax = ICA_ARminmax[1]\n",
    "#sigma2_ARminmax = ICA_ARminmax[2]\n",
    "#inf_ARminmax = ICA_ARminmax[3]\n",
    "#sup_ARminmax= ICA_ARminmax[4]\n",
    "#print(paste0(\"Valeur estimateur minmax \", delta_hat_ARminmax))\n",
    "#print(paste0(\"Variance estimateur Score a: \",sigma2_ARminmax))\n",
    "#print(paste0(\"Intervalle de confiance Score a: [\",inf_ARminmax,\",\",sup_ARminmax,\"]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Méthode de la variabe de contrôle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit l'estimateur de la variable de contôle de la manière suivante :\n",
    "\n",
    "\\begin{align*}\n",
    "\\widehat{\\delta}_{n}(b)=\\frac{1}{n} \\sum_{k=1}^{n}\\left[h\\left(\\mathbf{X}_{k}\\right)-b\\left\\{h_{0}\\left(\\mathbf{X}_{k}\\right)-m\\right\\}\\right]\\ avec \\ m=\\mathbb{E}[h_0(\\mathbf{X})]\n",
    "\\end{align*}\n",
    "\n",
    "Voici quelques propriétés de l'estimateurs:\n",
    "\n",
    "1. D'après le cours cet estimateur est fortement consistant par la loi forte des grands nombres et linéarité de l'espérance et sans biais.\n",
    "\n",
    "2. De plus on a :\n",
    "\n",
    "\n",
    "\\begin{align*} b^{\\star}=\\underset{b \\in \\mathbb{R}}{\\arg \\min } \\operatorname{Var}\\left[\\hat{\\delta}_{n}(b)\\right]=\\frac{\\operatorname{Cov}\\left[h(\\mathbf{X}), h_{0}(\\mathbf{X})\\right]}{\\operatorname{Var}\\left[h_{0}(\\mathbf{X})\\right]}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Pour calculer l'estimateur calculer la variable de contrôle il faut que l'on choisisse un $h_0$ tel dont on sache calculer  dont on sait calculer la moyenne : $m=\\mathbb{E}[h_0(\\mathbf{X})]$\n",
    "\n",
    "Ainsi, le choix de la fonction Score $\\mathcal{S}=\\frac{\\partial log\\mathcal{L_n}}{\\partial\\theta}$ ,avec $\\mathcal{L_n}$ la vraissemblace du modèle, apparait comme naturel.\n",
    "En effet, $S$ vérifie $\\mathbb{E}[\\mathcal{S}(\\mathbf{X})]=0$ pour n'importe quelle distribution. \n",
    "\n",
    "Dans le cas d'un échantillon $X_1....X_n$ selon la loi Gumbel , la fonction score derivée par rapport a $\\beta $est donnée par:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{S} (X_1, ...X_n)&=\\sum_{i=0}^n\\frac{(X_i-\\mu)}{\\beta^2}-\\frac{X_i-\\mu}{\\beta^2} exp(-\\frac{X_i-\\mu}{\\beta})-\\frac{n}{\\beta}\n",
    "\\end{align*}\n",
    "  \n",
    "La fonction score derivée par rapport a $\\mu $ est donnée par:\n",
    "\\begin{align*} \n",
    "\\mathcal{S} (X_1, ...X_n)=\\sum_{i=0}^n \\frac{1}{\\beta}exp(-\\frac{X_i-\\mu}{\\beta})+\\frac{n}{\\beta}\n",
    "\\end{align*}\n",
    "Ainsi, pour $h_0=\\mathcal{S}$ on a $m=0$, ce qui nous permet de définir l'estimateur suivant.\n",
    "\n",
    "\\begin{align*}\n",
    "\\widehat{\\delta}_{n}(b)=\\frac{1}{n} \\sum_{k=1}^{n}\\left[h\\left(\\mathbf{X}_{k}\\right)-b^{T}\\left\\{\\nabla_{\\theta}log\\mathcal{L_n}\\left(\\mathbf{X}_{k}\\right)\\right\\}\\right]\\ \\ avec \\ \\theta=(\\alpha,\\beta)\\in\\mathbb{R}^2 \\ et\\ b\\ \\in\\mathbb{R}^2\n",
    "\\end{align*}\n",
    "\n",
    "On remarque $$\\mathbb{E}[\\mathcal {S}(X)]=0\\Leftrightarrow \\mathbb{E}[\\frac{\\partial log(\\mathcal{L_n})}{\\partial\\alpha}]=\\mathbb{E}[\\frac{\\partial log(\\mathcal{L_n})}{\\partial\\beta}]=0$$\n",
    "\n",
    "On dispose alors de 3 choix pour $h_0$ :\n",
    "* $h_0=\\frac{\\partial log(\\mathcal{L_n})}{\\partial\\beta}$ \n",
    "* $h_0=\\frac{\\partial log(\\mathcal{L_n})}{\\partial\\alpha}$ \n",
    "* $h_0=\\nabla_{\\theta}log\\mathcal{L_n}=(\\frac{\\partial log(\\mathcal{L_n})}{\\partial\\alpha},\\frac{\\partial log(\\mathcal{L_n})}{\\partial\\beta})$ \n",
    "\n",
    "Voyons quels sont ceux qui nous donnent les meilleurs résultats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Valeur estimateur Score_b: 13.5555259424262\"\n",
      "[1] \"Variance estimateur Score_b: 5.6659900002206\"\n",
      "[1] \"Intervalle de confiance Score_b: [13.088989049305,14.0220628355473]\"\n",
      "[1] \"Carré du Coéfficient de correlation entre Score_b et delta: 0.105976311983586\"\n",
      "[1] \"Valeur estimateur Score_a: 13.2356020995442\"\n",
      "[1] \"Variance estimateur Score_a: 6.5641873500073\"\n",
      "[1] \"Intervalle de confiance Score_a: [12.7334461935112,13.7377580055771]\"\n",
      "[1] \"Carré du Coéfficient de correlation Score_a et delta: 0.0133574261140972\"\n",
      "[1] \"Valeur estimateur multidim: 13.4360225439088\"\n",
      "[1] \"Variance estimateur multidim: 4.0748898959684\"\n",
      "[1] \"Intervalle de confiance multidim: [13.0403772263045,13.8316678615132]\"\n"
     ]
    }
   ],
   "source": [
    "#### Code Score B:\n",
    "Score_b = function(x, a = 1, b = 2){\n",
    "  return(sum((x-a)/b^{2}-(x-a)/b^{2}*exp(-(x-a)/b)-1/b))\n",
    "}\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "estim_k_score_b = function(m =  100,   nb_pairs, a = 1, b = 2){\n",
    "  \n",
    "  # Création des vecteurs qui vont stocker les valeurs des min, max et du score \n",
    "  Min_vect = c()\n",
    "  Max_vect = c()\n",
    "  h_0 = c()\n",
    "  \n",
    "  # Simulation de nb_pairs échantillons de taille m\n",
    "  Z = simGumbel(nb_pairs*m, a, b)\n",
    "  M = matrix(Z,nrow=nb_pairs,byrow=TRUE)\n",
    "  \n",
    "  # Calcul du min et max de chaque échantillon + calcul de delta\n",
    "  Min_vect = apply(M,1,FUN=min)\n",
    "  Max_vect = apply(M,1,FUN=max)\n",
    "  delta = Max_vect-Min_vect\n",
    "  \n",
    "  # evaluation de la fonction score de notre échantillon\n",
    "  h_0 =  apply(M,1,FUN=Score_b)\n",
    "  \n",
    "  #Cacul de la constante b_star\n",
    "  cte = cov(h_0, delta)/var(h_0)\n",
    "  \n",
    "  return(cte)\n",
    "}\n",
    "k=estim_k_score_b(m =  100,   nb_pairs=100, a = 1, b = 2)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "estim_var_controle_Score_b= function(m  =  100,   nb_pairs, a = 1, b = 2){\n",
    "  \n",
    "  # Création des vecteurs qui vont stocker les valeurs des min,max et du score\n",
    "  Min_vect = c()\n",
    "  Max_vect = c()\n",
    "  h_0 = c()  \n",
    "  \n",
    "  # Calcul de la constante b_star\n",
    "  k = estim_k_score_b(m, nb_pairs, a, b)\n",
    "  \n",
    "  # Simulation de nb_pairs échantillons de taille m\n",
    "  Z = simGumbel(nb_pairs*m, a, b)\n",
    "  M = matrix(Z,nrow=nb_pairs,byrow=TRUE)\n",
    "  \n",
    "  # Calcul du min et max de chaque échantillon + calcul de delta\n",
    "  Min_vect = apply(M,1,FUN=min)\n",
    "  Max_vect = apply(M,1,FUN=max)\n",
    "  delta = Max_vect-Min_vect\n",
    "  \n",
    "  # evaluation de la fonction score de notre échantillon\n",
    "  h_0 = apply(M,1,FUN=Score_b)\n",
    "  \n",
    "  #evaluation de la statistique de la variable de contrôle + calcul de sa variance\n",
    "  estim_controle =  mean(delta-k*(h_0))\n",
    "  var_estim =  var (delta-k*(h_0))\n",
    "  \n",
    "  #evaluation des bornes de l'intervalle de confiance\n",
    "  inf=estim_controle-qnorm(0.975,0,1)*sqrt(var_estim/nb_pairs)\n",
    "  sup=estim_controle+qnorm(0.975,0,1)*sqrt(var_estim/nb_pairs)\n",
    "  \n",
    "  #calcul de la covariance entre delta et la fonction score b\n",
    "  coR= cor(delta,h_0)\n",
    "  \n",
    "  return(c(estim_controle, var_estim, inf, sup, coR^2))\n",
    "}\n",
    "\n",
    " \n",
    "\n",
    "controle_Score_b=estim_var_controle_Score_b(m  =  100,   nb_pairs = 100, a = 1, b = 2)\n",
    "delta_ctrl_b=controle_Score_b[1]\n",
    "sigma2_b=controle_Score_b[2]\n",
    "inf_b=controle_Score_b[3]\n",
    "sup_b=controle_Score_b[4]\n",
    "coR_b=controle_Score_b[5]\n",
    "\n",
    " \n",
    "\n",
    "print(paste0(\"Valeur estimateur Score_b: \",delta_ctrl_b))\n",
    "print(paste0(\"Variance estimateur Score_b: \",sigma2_b))\n",
    "print(paste0(\"Intervalle de confiance Score_b: [\" ,inf_b, \",\" ,sup_b, \"]\"))\n",
    "print(paste0(\"Carré du Coéfficient de correlation entre Score_b et delta: \", coR_b))\n",
    "\n",
    " \n",
    "\n",
    "### score A:\n",
    "\n",
    " \n",
    "\n",
    "Score_a = function(x, a=1, b=2){\n",
    "  return(sum(-1/b*exp(-(x-a)/b)+1/b))\n",
    "}\n",
    "\n",
    " \n",
    "\n",
    "# Fonction qui estime b_star (=la constante qui minimise la variance de l'estimateur) avec h_0=Score_a\n",
    "\n",
    " \n",
    "\n",
    "estim_k_score_a = function(m , nb_pairs, a , b ){\n",
    "  \n",
    "  # Création des vecteurs qui vont stocker les valeurs des min, max et du score \n",
    "  Min_vect = c()\n",
    "  Max_vect = c()\n",
    "  h_0 = c()\n",
    "  \n",
    "  # Simulation de nb_pairs échantillons de taille m\n",
    "  Z = simGumbel(nb_pairs*m, a, b)\n",
    "  M = matrix(Z,nrow=nb_pairs,byrow=TRUE)\n",
    "  \n",
    "  # Calcul du min et max de chaque échantillon + calcul de delta\n",
    "  Min_vect = apply(M,1,FUN=min)\n",
    "  Max_vect = apply(M,1,FUN=max)\n",
    "  delta = Max_vect-Min_vect\n",
    "  \n",
    "  # evaluation de la fonction score de notre échantillon\n",
    "  h_0 =  apply(M,1,FUN=Score_a)\n",
    "  \n",
    "  #Cacul de la constante b_star\n",
    "  cte = cov(h_0,  delta)/var(h_0)\n",
    "  \n",
    "  return(cte)\n",
    "}\n",
    "\n",
    " \n",
    "\n",
    "k=estim_k_score_a(m =  100,   nb_pairs=100, a = 1, b = 2) #ici k=b_star\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "estim_var_controle_Score_a = function(m ,   nb_pairs, a , b ){\n",
    "  \n",
    "  # Création des vecteurs qui vont stocker les valeurs des min,max et du score\n",
    "  Min_vect = c()\n",
    "  Max_vect = c()\n",
    "  h_0 = c()  \n",
    "  \n",
    "  # Calcul de la constante b_star\n",
    "  k = estim_k_score_a(m, nb_pairs, a, b)\n",
    "  \n",
    "  # Simulation de nb_pairs échantillons de taille m\n",
    "  Z = simGumbel(nb_pairs*m, a, b)\n",
    "  M = matrix(Z,nrow=nb_pairs,byrow=TRUE)\n",
    "  \n",
    "  # Calcul du min et max de chaque échantillon + calcul de delta\n",
    "  Min_vect = apply(M,1,FUN=min)\n",
    "  Max_vect = apply(M,1,FUN=max)\n",
    "  delta = Max_vect-Min_vect\n",
    "  \n",
    "  # evaluation de la fonction score de notre échantillon\n",
    "  h_0 = apply(M,1,FUN=Score_a)\n",
    "  \n",
    "  #evaluation de la statistique de la variable de contrôle + calcul de sa variance\n",
    "  estim_controle =  mean(delta-k*(h_0))\n",
    "  var_estim =  var (delta-k*(h_0))\n",
    "  \n",
    "  #evaluation des bornes de l'intervalle de confiance\n",
    "  inf=estim_controle-qnorm(0.975,0,1)*sqrt(var_estim/nb_pairs)\n",
    "  sup=estim_controle+qnorm(0.975,0,1)*sqrt(var_estim/nb_pairs)\n",
    "  \n",
    "  #calcul de la covariance entre delta et la fonction score a\n",
    "  coR = cor(delta,h_0)\n",
    "  \n",
    "  return(c(estim_controle, var_estim, inf, sup, coR^2))\n",
    "}\n",
    "\n",
    " \n",
    "\n",
    "controle_Score_a=estim_var_controle_Score_a(m  =  100,   nb_pairs = 100, a = 1, b = 2)\n",
    "delta_ctrl_a=controle_Score_a[1]\n",
    "sigma2_a=controle_Score_a[2]\n",
    "inf_a=controle_Score_a[3]\n",
    "sup_a=controle_Score_a[4]\n",
    "coR_a=controle_Score_a[5]\n",
    "\n",
    " \n",
    "\n",
    "print(paste0(\"Valeur estimateur Score_a: \",delta_ctrl_a))\n",
    "print(paste0(\"Variance estimateur Score_a: \",sigma2_a))\n",
    "print(paste0(\"Intervalle de confiance Score_a: [\",inf_a,\",\",sup_a,\"]\"))\n",
    "print(paste0(\"Carré du Coéfficient de correlation Score_a et delta: \", coR_a))\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "#### Score Multidim\n",
    "\n",
    " \n",
    "\n",
    "##### Variable de contrôle multdimensionnelle\n",
    "\n",
    " \n",
    "\n",
    "estim_k_multidim = function(m , nb_pairs, a, b ){\n",
    "  \n",
    "  # Simulation de nb_pairs echantillons de taille m (lignes de la matrice = un échantillon de taille m)\n",
    "  Z = simGumbel(m*nb_pairs, a, b)\n",
    "  M=matrix(Z,nrow=nb_pairs)\n",
    "  \n",
    "  # evaluation du min,max, Score a, score B \n",
    "  Min_vect = apply(M,1,FUN=min)\n",
    "  Max_vect = apply(M,1,FUN=max)\n",
    "  h_0 = apply(M,1,FUN=Score_a)\n",
    "  h_1 = apply(M,1,FUN=Score_b)\n",
    "  \n",
    "  # Calcul de delta\n",
    "  delta = Max_vect-Min_vect\n",
    "  \n",
    "  # Calcul du gradient\n",
    "  m = matrix(c(h_0, h_1), ncol = 2)\n",
    "  \n",
    "  # Calcul de la matrice de variance covariance du gradient\n",
    "  cov_inv = inv(cov(m))\n",
    "  \n",
    "  #calcul de la matrice de covariance du gradient et delta\n",
    "  cov1 = c(cov(h_0, delta), cov(h_1, delta))\n",
    "  coR= (1/var(delta))*t(cov1) %*% cov_inv %*% cov1\n",
    "\n",
    "  return(c(cov_inv %*% cov1, coR ) )  #retourne le produit matriciel des deux matrices \n",
    "}\n",
    "\n",
    " \n",
    "\n",
    "estim_var_controle_multidim = function(m,   nb_pairs, a , b){\n",
    "  \n",
    "  # Simulation de nb_pairs echantillons de taille m (lignes de la matrice = un échantillon de taille m)\n",
    "  Z = simGumbel(m*nb_pairs, a, b)\n",
    "  M=matrix(Z,nrow=nb_pairs)\n",
    "  \n",
    "  # evaluation de min,max, Score a, score B\n",
    "  Min_vect = apply(M,1,FUN=min)\n",
    "  Max_vect = apply(M,1,FUN=max)\n",
    "  h_0 = apply(M,1,FUN=Score_a)\n",
    "  h_1 = apply(M,1,FUN=Score_b)\n",
    "  \n",
    "  #calcul du delta des échantillons\n",
    "  delta = Max_vect-Min_vect\n",
    "  \n",
    "  #calcul de la du vecteur qui minimise la variance par la fonction estim_k_multidim\n",
    "  k1 = estim_k_multidim(m, nb_pairs, a, b) [1]\n",
    "  k2 = estim_k_multidim(m, nb_pairs, a, b) [2]\n",
    "  k = c(k1, k2)\n",
    "  \n",
    "  #Exection du produit matriciel, pour évaluer l'estimateur ainsi que sa variance\n",
    "  m = matrix(c(h_0, h_1), ncol = 2)\n",
    "  \n",
    "  z=delta-m%*%k\n",
    "  estim_controle = mean(z)\n",
    "  var_estim = var(z)\n",
    "  \n",
    "  #évaluation des bornes de l'intervalle de confiance\n",
    "  inf=estim_controle-qnorm(0.975,0,1)*sqrt(var_estim/nb_pairs)\n",
    "  sup=estim_controle+qnorm(0.975,0,1)*sqrt(var_estim/nb_pairs)\n",
    "  \n",
    "  #calcul du coefficient de correlation entre \n",
    "  \n",
    "  coR =  estim_k_multidim(m, nb_pairs, a, b) [3]\n",
    "  return(c(estim_controle, var_estim,inf,sup,coR ))\n",
    "}\n",
    "\n",
    " \n",
    "\n",
    "controle_multidim=estim_var_controle_multidim(m  =  100,   nb_pairs = 100, a = 1, b = 2)\n",
    "delta_hat_multidim=controle_multidim[1]\n",
    "sigma2_multidim=controle_multidim[2]\n",
    "inf_multidim=controle_multidim[3]\n",
    "sup_multidim=controle_multidim[4]\n",
    "\n",
    " \n",
    "\n",
    "print(paste0(\"Valeur estimateur multidim: \",delta_hat_multidim))\n",
    "print(paste0(\"Variance estimateur multidim: \",sigma2_multidim))\n",
    "print(paste0(\"Intervalle de confiance multidim: [\",inf_multidim,\",\",sup_multidim,\"]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Commentaires:\n",
    "\n",
    "Chacune des méthodes semble approximer avec un degrès de précision $\\delta$ du même ordre. L'estimateur de la variable de contrôle est toujours roche de 13.5 avec une variance proche de 6.  Calculons leurs efficacités relatives pour voir si ces méthodes sont plus performantes que celle de Monte-Carlo.\n",
    "\n",
    "\n",
    "On definit l'efficacité relative de l'estimateur Y issu de l'algo (f), par rapport à la méthode de Monte carlo de la manière suivante:\n",
    "\n",
    "\n",
    "$$éfficacité\\ relative (f) =\\ \\frac{(temps\\ d'éxécution\\ de\\ l'algorithme\\ de\\ M-C)*(variance\\ de\\ l'estimatateur\\ de\\ M-C)}{ (temps\\ d'éxécution\\ de\\ l'algorithme\\ de\\ f)*(variance\\ de\\ l'estimatateur\\ Y)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Variance moyenne de  Monte Carlo vs variable de contrôle score b:6.69330001620027 vs 5.91930423597451\"\n",
      "[1] \" Efficacité relative:  Monte Carlo vs variable de contrôle Score b: 0.294545061127081\"\n",
      "[1] \"Variance moyenne de Monte Carlo vs  variable de contrôle score a: 6.77434548818255 vs 6.85080109873097\"\n",
      "[1] \" Efficacité relative: Monte Carlo vs  variable de contrôle Score_a :  0.197185659927126\"\n",
      "[1] \"Variance moyenne de Monte Carlo vs  variable de contrôle score multidim : 7.00800973457538 vs 5.74555433706936\"\n",
      "[1] \" Efficacité relative: Monte Carlo vs  variable de contrôle Score_multidim:  0.113354908491889\"\n"
     ]
    }
   ],
   "source": [
    "#CALCULS DES EFFICACITÉS RELATIVES ENTRE LA LA METHODE DE LA VARIABLE DE CONTRÔLE (AUX FONCTIONS SCORE) ET LA MÉTHODE DE MONTE CARLO CLASSIQUE\n",
    "\n",
    "############ efficacité relative Monte_carlo_Score_b\n",
    "\n",
    "efficacite_relative_Score_b_Monte_carlo= function(nb_fois, m , nb_pairs, a = 1, b = 2){\n",
    "    \n",
    "    n=nb_pairs\n",
    "    mu=a\n",
    "    beta=b\n",
    "        \n",
    "    # effectue une moyenne du temps d'éxécution sur \"nb_fois\" éxécutions pour la fonction estim_var_controle_Score_b\n",
    "    benchmark_Score_b  =  mean(microbenchmark(estim_var_controle_Score_b(m , nb_pairs , a , b ), times = nb_fois)$time)\n",
    "  \n",
    "    # variance moyenne de sur \"nb_fois\" appels à la variable de contrôle avec h_0= Score_b\n",
    "    var_Score_b  =  mean(sapply(rep(m, nb_fois), estim_var_controle_Score_b,nb_pairs=n, a=mu , b=beta)[2,])\n",
    "\n",
    "  # effectue une moyenne du temps d'éxécution sur \"nb_fois\" éxécutions pour la fonction ICA_asymptotique_minmaxGumbel\n",
    "  benchmark_Monte_Carlo  =  mean(microbenchmark(ICA_asymptotique_minmaxGumbel(m , nb_pairs , a , b ),times= nb_fois)$time)\n",
    "  \n",
    "  #variance moyenne sur \"nb_fois\" appels  à la de l'estimateur de monte carlo\n",
    "    var_Monte_Carlo =  mean(sapply(rep(m, nb_fois), ICA_asymptotique_minmaxGumbel, nb_pairs=n, a=mu , b=beta )[2,])\n",
    "  \n",
    "  print(paste0(\"Variance moyenne de  Monte Carlo vs variable de contrôle score b:\",\n",
    "               var_Monte_Carlo,\" vs \", var_Score_b ))\n",
    "\n",
    "\n",
    "return((benchmark_Monte_Carlo*var_Monte_Carlo)/(benchmark_Score_b*var_Score_b))\n",
    "}\n",
    "\n",
    "\n",
    "eff_Score_b_MC=efficacite_relative_Score_b_Monte_carlo(nb_fois=100, nb_pairs=100, m=100, a=1, b=2)\n",
    "print(paste0(\" Efficacité relative:  Monte Carlo vs variable de contrôle Score b: \", eff_Score_b_MC))\n",
    "\n",
    "\n",
    "\n",
    "########## efficacite relative score_a / Monte carlo\n",
    "\n",
    "efficacite_relative_Score_a_Monte_carlo= function(nb_fois, m , nb_pairs, a = 1, b = 2){\n",
    "    n=nb_pairs\n",
    "    mu=a\n",
    "    beta=b\n",
    "    \n",
    "  benchmark_Score_a  =  mean(microbenchmark(estim_var_controle_Score_a(m , nb_pairs , a , b ), times = nb_fois)$time)\n",
    "  var_Score_a  =  mean(sapply(rep(m, nb_fois), estim_var_controle_Score_a,nb_pairs=n, a=mu , b=beta)[2,])\n",
    "\n",
    "  \n",
    "  benchmark_Monte_Carlo  =  mean(microbenchmark(ICA_asymptotique_minmaxGumbel(m , nb_pairs , a , b ),times= nb_fois)$time)\n",
    "  var_Monte_Carlo =  mean(sapply(rep(m, nb_fois), ICA_asymptotique_minmaxGumbel, nb_pairs=n, a=mu , b=beta )[2,])\n",
    "\n",
    "    print(paste0(\"Variance moyenne de Monte Carlo vs  variable de contrôle score a: \",\n",
    "                 var_Monte_Carlo,\" vs \", var_Score_a ))\n",
    "\n",
    "return((benchmark_Monte_Carlo*var_Monte_Carlo)/(benchmark_Score_a*var_Score_a))\n",
    "}\n",
    "\n",
    "eff_Score_a_MC=efficacite_relative_Score_a_Monte_carlo(nb_fois=100, nb_pairs=100, m=100, a=1, b=2)\n",
    "print(paste0(\" Efficacité relative: Monte Carlo vs  variable de contrôle Score_a :  \",\n",
    "             eff_Score_a_MC))\n",
    "\n",
    "\n",
    "############ efficacite relative Score multidim/ Montecarlo:\n",
    "\n",
    "efficacite_relative_Score_multidim_Monte_carlo= function(nb_fois, m , nb_pairs, a = 1, b = 2){\n",
    "    n=nb_pairs\n",
    "    mu=a\n",
    "    beta=b\n",
    "    \n",
    "  benchmark_Score_multidim  =  mean(microbenchmark(estim_var_controle_multidim(m , nb_pairs , a , b ),times= nb_fois)$time)\n",
    "  var_Score_multidim =  mean(sapply(rep(m, nb_fois), estim_var_controle_multidim, nb_pairs=n, a=mu , b=beta )[2,])\n",
    "  \n",
    "  benchmark_Monte_Carlo  =  mean(microbenchmark(ICA_asymptotique_minmaxGumbel(m , nb_pairs , a , b ),times= nb_fois)$time)\n",
    "  var_Monte_Carlo =  mean(sapply(rep(m, nb_fois), ICA_asymptotique_minmaxGumbel, nb_pairs=n, a=mu , b=beta )[2,])\n",
    "  \n",
    "  print(paste0(\"Variance moyenne de Monte Carlo vs  variable de contrôle score multidim : \", \n",
    "               var_Monte_Carlo,\" vs \", var_Score_multidim ))\n",
    "\n",
    "\n",
    "return((benchmark_Monte_Carlo*var_Monte_Carlo)/(benchmark_Score_multidim*var_Score_multidim))\n",
    "}\n",
    "\n",
    "eff_Score_multidim_MC=efficacite_relative_Score_multidim_Monte_carlo(nb_fois=100, nb_pairs=100, m=100, a=1, b=2)\n",
    "print(paste0(\" Efficacité relative: Monte Carlo vs  variable de contrôle Score_multidim:  \",\n",
    "             eff_Score_multidim_MC))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remarques\n",
    "\n",
    "On constate que l'éfficacité relative entre la méthode de Monte-Carlo et la méthode de la variable de contrôle dont la variable de contrôle est une des fonctions Score est toujours inférieure à 1.\n",
    "\n",
    "Cette dernière est proche de 0.6 Cela signifie que la méthode de Monte-Carlo est plus perfomante que la méthode de la variable de contrôle dont le contrôle est la fonction score (unidimensionnelle et multidimensionnelle).\n",
    "\n",
    "Ceci peut paraître surprenant car la moyennes des variances de chaque estimateur semble similaire. On peut même remarquer une légère diminution de la variance pour les estimateurs de la variable de contrôle.\n",
    "\n",
    "On en déduit que le temps d'éxécutions de la méthode de Monte Carlo est bien supérieur au gain de variance permis par la méthode de la variable de contrôle. En témoignent, le carré des coéfficients de corrélations (voir ci-dessous) qui sont inférieurs à 0.3. Plus ce coefficient est proche de 1, plus la variance diminue en vertu de la relation qui suit:\n",
    "\n",
    "$\\operatorname{var}\\left[\\hat{\\delta}_{n}\\left(b^{\\star}\\right)\\right]=\\operatorname{Var}\\left[\\bar{h}_{n}\\right]\\left(1-\\rho\\left(h(\\mathbf{X}), h_{0}(\\mathbf{X})\\right)^{2}\\right), \\quad \\rho\\left(h(\\mathbf{X}), h_{0}(\\mathbf{X})\\right)=\\frac{\\operatorname{Cov}\\left[h(\\mathbf{X}), h_{0}(\\mathbf{X})\\right]}{\\sqrt{\\operatorname{Var}[h(\\mathbf{X})] \\operatorname{Var}\\left[h_{0}(\\mathbf{X})\\right]}}$\n",
    "\n",
    "La même relation pour le cas mulidimensionel:\n",
    "\n",
    "$b^{\\star}=\\Sigma_{\\mathbf{Z}}^{-1} \\Sigma_{h(\\mathbf{X}), \\mathbf{Z}}$\n",
    "et $\\operatorname{Var}\\left[\\widehat{\\delta}_{n}\\left(b^{\\star}\\right)\\right]=\\operatorname{Var}\\left[\\bar{h}_{n}\\right]\\left(1-\\frac{1}{\\operatorname{Var}[h(\\mathbf{X})]} \\Sigma_{h(\\mathbf{X}), \\mathbf{Z}}^{T} \\Sigma_{\\mathbf{Z}}^{-1} \\Sigma_{h(\\mathbf{X}), \\mathbf{Z}}\\right)$\n",
    "avec $\\Sigma_{h(\\mathbf{X}), \\mathbf{Z}}$ la matrice de dimensions $n*1$ où le i-ème coefficient est \n",
    "\n",
    "$\\operatorname{Cov}(h(\\mathbf{X}),h_i(\\mathbf{X}))$ et $\\Sigma_{\\mathbf{Z}}$ la matrice de covariance de covariance de $\\mathbf{Z}=(h_1(\\mathbf{X}),...,h_n(\\mathbf{X}))\\in \\mathbb{R}^n$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Carré du Coéfficient de correlation entre variable de contrôle Score_b et delta: 0.100016663841343\"\n",
      "[1] \"Carré du Coéfficient de correlation entre variable de contrôle Score_a et delta: 0.000103432108380488\"\n",
      "[1] \"Carré du Coéfficient de correlation entre Score_multidim et delta: 0.192770191491194\"\n"
     ]
    }
   ],
   "source": [
    "controle_Score_a=estim_var_controle_Score_a(m  =  100,   nb_pairs = 100, a = 1, b = 2)\n",
    "coR_a=controle_Score_a[5]\n",
    "\n",
    "controle_Score_b=estim_var_controle_Score_b(m  =  100,   nb_pairs = 100, a = 1, b = 2)\n",
    "coR_b=controle_Score_b[5]\n",
    "\n",
    "controle_Score_multidim=estim_var_controle_multidim(m  =  100,   nb_pairs = 100, a = 1, b = 2)\n",
    "coR_multidim=controle_Score_multidim[5]\n",
    "\n",
    "\n",
    "print(paste0(\"Carré du Coéfficient de correlation entre variable de contrôle Score_b et delta: \", coR_b))\n",
    "print(paste0(\"Carré du Coéfficient de correlation entre variable de contrôle Score_a et delta: \", coR_a))\n",
    "print(paste0(\"Carré du Coéfficient de correlation entre Score_multidim et delta: \", coR_multidim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimation de la variable de contrôle par la variance:\n",
    "\n",
    "Si le précédent choix de $h_0$ par la fonction score parait pratique de part la facilité à calculer son ésperance, on constate qu'il n'est pas pour autant optimal. La corrélation avec delta est trop faible pour pouvoir impacter significativement la variance au regard du temps d'éxécution du code de la méthode de la variance.\n",
    "\n",
    "C'est pourquoi, $\\widehat{\\sigma}_{n-1}^{2}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}_{n}\\right)^{2}$ avec $(X_i)_{i\\geq1}$ des variables i.i.d suivant la loi de Gumbel(1,2) s'avère intuitivement être un bon candidat. \n",
    "\n",
    "En effet, la variance empirique est aussi un critère de dispersion: elle est donc corrélée à $\\Delta$. Elle est sans biais de moyenne connue: $Var(X)=\\frac{2}{3}\\pi$ (car $\\beta=2$).\n",
    "\n",
    "Vérifions à l'aide de l'algorithme ci dessous notre intuition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Valeur estimateur de variable de contrôle variance empirique: 13.5775019135941\"\n",
      "[1] \"Variance estimateur de variable de contrôle variance empirique: 3.09639891382205\"\n",
      "[1] \"Intervalle de confiance variable de contrôle variance emprique [13.5430132358579,13.6119905913302]\"\n",
      "[1] \"Carré du Coéfficient de correlation entre variance empirique et delta: 0.527742668437265\"\n"
     ]
    }
   ],
   "source": [
    "#####   Choix de la variance comme Variable de contrôle\n",
    "\n",
    "#on estime la covariance entre s et delta// Vérification:\n",
    "estim_var_control_var = function(nb_pairs, m = 100, a = 1, b = 2){\n",
    "    \n",
    "    ####### Chauffe pour la constante b ##########################################\n",
    "     \n",
    "    \n",
    "    # Simulation de nb_pairs d'échantillons de taille m ( 1 ligne de la matrice= 1 échantillon de taille m)\n",
    "    Z = simGumbel(nb_pairs*m, a, b)\n",
    "    M = matrix(Z,nrow=nb_pairs)\n",
    "    \n",
    "    # Evaluation du max,min, et h_0 sur chaque échantillon\n",
    "    Min_vect = apply(M, 1, FUN=min)\n",
    "    Max_vect = apply(M, 1, FUN=max)\n",
    "    h_0= apply(M, 1, FUN=var)\n",
    "    \n",
    "    # Calcul de delta\n",
    "    delta  =  Max_vect - Min_vect\n",
    "\n",
    "    # Calcul de la constante qui minimise la variance de l'estimateur de la var de controle\n",
    "    cte = cov(delta ,  h_0)/var(h_0)\n",
    "  \n",
    "    # espérance de la variable de controle: variance car h_0 est par défaut l'estimateur de la variance sans biais\n",
    "    e  =  (b**2)*(pi**2)/6\n",
    "    \n",
    "    ############### Fin de la chauffe   pour le calcul de la constante ##############\n",
    "  \n",
    "    # Simulation de nb_pairs d'échantillons de taille m ( 1 ligne de la matrice= 1 échantillon de taille m)\n",
    "    Z = simGumbel(nb_pairs*m, a, b)\n",
    "    M = matrix(Z,nrow=nb_pairs)\n",
    "    \n",
    "    # Evaluation du max,min, et h_0 sur chaque échantillon\n",
    "    Min_vect = apply(M, 1, FUN=min)\n",
    "    Max_vect = apply(M, 1, FUN=max)\n",
    "    h_0= apply(M, 1, FUN=var)\n",
    "    \n",
    "    # Calcul de delta\n",
    "    delta  =  Max_vect - Min_vect\n",
    "    \n",
    "    # calcul de l'estimateur de controle et de sa variance\n",
    "    delta_ctrl  =  mean(delta - cte*(h_0-e))\n",
    "    sigma2_ctrl  =  var(delta - cte*(h_0-e))\n",
    "  \n",
    "    # Calcul du coefficient de corrélation entre h_0 et delta\n",
    "    coR= cor(h_0,delta)\n",
    "    \n",
    "    # Calcul de l'intervalle de confiance \n",
    "    q  =  qnorm(0.975)\n",
    "    inf= delta_ctrl - q *sqrt(sigma2_ctrl)/nb_pairs\n",
    "    sup= delta_ctrl +q *sqrt(sigma2_ctrl)/nb_pairs\n",
    "  \n",
    "  return(c(delta_ctrl, sigma2_ctrl,inf,sup,coR^2))\n",
    "}\n",
    "\n",
    "controle_var = estim_var_control_var(m  =  100,   nb_pairs = 100, a = 1, b = 2)\n",
    "delta_ctrl_var = controle_var[1]\n",
    "sigma2_var = controle_var[2]\n",
    "inf_var = controle_var[3]\n",
    "sup_var = controle_var[4]\n",
    "coR_var = controle_var[5]\n",
    "\n",
    "print(paste0(\"Valeur estimateur de variable de contrôle variance empirique: \",delta_ctrl_var))\n",
    "print(paste0(\"Variance estimateur de variable de contrôle variance empirique: \",sigma2_var))\n",
    "print(paste0(\"Intervalle de confiance variable de contrôle variance emprique [\" ,inf_var, \",\" ,sup_var, \"]\"))\n",
    "print(paste0(\"Carré du Coéfficient de correlation entre variance empirique et delta: \", coR_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"variance moyenne  pour Monte Carlo Classique:6.84440994829626\"\n",
      "[1] \"variance moyenne avec  la variance empirique comme variable de contrôle:3.03591720919571\"\n",
      "[1] \" Efficacité relative:  Monte Carlo / variable de contrôle variance empirique: 0.586508964701466\"\n"
     ]
    }
   ],
   "source": [
    "##### Éfficacité relative par rapport à la méthode de variable de controle h_0=var empirique\n",
    "\n",
    "efficacite_relative_ctrl_var_Monte_carlo= function(nb_fois, m , nb_pairs, a = 1, b = 2){\n",
    "    \n",
    "    n=nb_pairs\n",
    "    mu=a\n",
    "    beta=b\n",
    "    \n",
    "    \n",
    "  benchmark_ctrl_var  =  mean(microbenchmark(estim_var_control_var(m , nb_pairs , a , b ), times = nb_fois)$time)\n",
    "  var_ctrl_var  =  mean(sapply(rep(m, nb_fois), estim_var_control_var,nb_pairs=n, a=mu , b=beta)[2,])\n",
    "\n",
    "  \n",
    "  benchmark_Monte_Carlo  =  mean(microbenchmark(ICA_asymptotique_minmaxGumbel(m , nb_pairs , a , b ),times= nb_fois)$time)\n",
    "  var_Monte_Carlo =  mean(sapply(rep(m, nb_fois), ICA_asymptotique_minmaxGumbel, nb_pairs=n, a=mu , b=beta )[2,])\n",
    "  \n",
    "  print(paste0(\"variance moyenne  pour Monte Carlo Classique:\", var_Monte_Carlo ))\n",
    "  print(paste0(\"variance moyenne avec  la variance empirique comme variable de contrôle:\",  var_ctrl_var ))\n",
    "\n",
    "\n",
    "return((benchmark_Monte_Carlo*var_Monte_Carlo)/(benchmark_ctrl_var*var_ctrl_var))\n",
    "}\n",
    "\n",
    "\n",
    "eff_MC_var=efficacite_relative_ctrl_var_Monte_carlo(nb_fois=100, nb_pairs=100, m=100, a=1, b=2)\n",
    "print(paste0(\" Efficacité relative:  Monte Carlo / variable de contrôle variance empirique: \", eff_MC_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Commentaires:\n",
    "\n",
    "1. On remarque que l'efficacité relative est proche de 0.5.. Ainsi, d'après les discussions précédentes cela signifie que la méthode de la variable de contrôle avec la variance empirique comme variable de contrôle est deux fois moins efficace que la méthode de Monte Carlo classique pour estimer $\\delta$; et ce , malgré le fait qu'elle reduise de moitié la variance .                                                                               La réduction de variance illustre la relation qui existe entre corrélation de $\\Delta$ et $h_0$ et niveau de variance de l'estimateur. Ici le carré du coefficient de corrélation est plus de deux fois supérieur à celui qui existe pour les fonctions Score (proche de 0.6). Il a permis de réduire la variance de plus de  moitié par rapport à l'estimateur de Monte Carlo classique en raison de la forte corrélation qui existe entre la variance et l'etendue de l'echantillon. \n",
    "\n",
    "2. Malgré que la variance soit moitié moindre que celle de l'estimateur de Monte Carlo classique,  ce dernier estimateur reste relativement plus efficace que celui de la variable de contrôle. Le coût de execution  quadruple pour  pour la méthode de variable de contrôle (a cause de la periode de chauffe pour estimer la constante b, qui entraine plus de calculs et deux fois plus de simulations au total ) avec $h_0=\\widehat{\\sigma}_{n-1}^{2}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}_{n}\\right)^{2}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'extraDistr'\n",
      "\n",
      "The following objects are masked _by_ '.GlobalEnv':\n",
      "\n",
      "    dgumbel, pgumbel\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(\"extraDistr\")\n",
    "library(\"matlib\")\n",
    "library(\"microbenchmark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie III – Estimation d’un événement rare\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 : Méthode de Monte Carlo classique\n",
    "\n",
    "On veut trouver la densite $f$ de $V_{(n)}$. Pour cela on va trouver la fonction de répartition $F$\n",
    "\n",
    "\\begin{array} { l }\n",
    "{F(x)= \\mathbb{P} (V_{(n)} < x) } \\\\ \n",
    "{F(x)= \\displaystyle\\prod_{i=1}^{n} \\mathbb{P}(V_{i} < x) } \\\\\n",
    "{F(x) = \\displaystyle\\prod_{i=1}^{n} (1-e^{-\\lambda x } ) } \\\\\n",
    "{f(x) = n\\lambda e^{-\\lambda x}(1-e^{-\\lambda x })^{n-1} }\\\\\n",
    "{p = \\mathbb{P} (V_{(n)} > t)  = \\displaystyle\\int_{t}^{\\infty} n\\lambda e^{-\\lambda x}(1-e^{-\\lambda x })^{n-1} dx }\n",
    "\\end{array}\n",
    "\n",
    "On définit ainsi notre estimateur de monte carlo classique\n",
    "$ \\widehat{p} = \\displaystyle\\sum_{i=1}^{m} (1-e^{-\\lambda X_{i} })^{n-1} \\mathbb{1}_{X_{i}>t}$ ,\n",
    "\n",
    "avec les $X_{i}$ générés selon une loi exponentielle de paramètre $\\lambda$ et $m$ le nombre de réalisations \n",
    "\n",
    "On retourne l'intervalle de confiance asymptotique\n",
    "\n",
    "$\\mathrm{IC}_{1-\\alpha}=\\left[\\hat{p}_{n}-q_{1-\\alpha / 2} \\sqrt{\\frac{\\sigma^{2}}{n}}, \\hat{p}_{n}+q_{1-\\alpha / 2} \\sqrt{\\frac{\\sigma^{2}}{n}}\\right] \\quad$ avec $\\quad \\Phi\\left(q_{1-a / 2}\\right)=1-\\frac{\\alpha}{2}$\n",
    "\n",
    "et $\\sigma^{2}$ la variance empirique de $(1-e^{-\\lambda X_{i} })^{n-1} \\mathbb{1}_{X_{i}>t}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Estimation de p: 0\"\n",
      "[1] \"Intervalle de Confiance: 0 0\"\n",
      "[1] \"Estimation de p: 0\"\n",
      "[1] \"Intervalle de Confiance: 0 0\"\n"
     ]
    }
   ],
   "source": [
    "# Methode de Monte Carlo classique\n",
    "\n",
    "estim_rare_classique = function(nb_realisations  =  1000, lambda  =  2, t =  8, n  =  1000){\n",
    "    x  =  rexp(nb_realisations, lambda)\n",
    "\n",
    "\n",
    "    indicatrice  =  ifelse(x>t,  1,  0)\n",
    "    p_hat  =  mean(n*(1-exp(-lambda*x))^(n-1)*indicatrice)\n",
    "\n",
    "    sigma2_p  =  var(n*(1-exp(-lambda*x))^(n-1)*indicatrice) # variance\n",
    "\n",
    "    return (c(p_hat, sigma2_p))\n",
    "\n",
    "}\n",
    "\n",
    "estim_classique = estim_rare_classique()\n",
    "p_hat = estim_classique[1]\n",
    "sigma2_p  = estim_classique[2]\n",
    "\n",
    "print(paste0(\"Estimation de p: \", p_hat))\n",
    "q  =  qnorm(0.975)\n",
    "print(paste0(\"Intervalle de Confiance: \",  p_hat + q *sqrt(sigma2_p/nb_realisations),  \" \",  p_hat - q *sqrt(sigma2_p/nb_realisations)))\n",
    "\n",
    "\n",
    "# estimation monte carlo classique avec 10000 tirages\n",
    "\n",
    "estim_rare_classique = function(nb_realisations  =  1000, lambda  =  2, t =  8, n  =  1000){\n",
    "    x  =  rexp(nb_realisations, lambda)\n",
    "\n",
    "\n",
    "    indicatrice  =  ifelse(x>t,  1,  0)\n",
    "    p_hat  =  mean(n*(1-exp(-lambda*x))^(n-1)*indicatrice)\n",
    "\n",
    "    sigma2_p  =  var(n*(1-exp(-lambda*x))^(n-1)*indicatrice) # variance\n",
    "\n",
    "    return (c(p_hat, sigma2_p))\n",
    "\n",
    "}\n",
    "\n",
    "estim_classique = estim_rare_classique( nb_realisations = 100000 )\n",
    "p_hat = estim_classique[1]\n",
    "sigma2_p  = estim_classique[2]\n",
    "\n",
    "print(paste0(\"Estimation de p: \", p_hat))\n",
    "q  =  qnorm(0.975)\n",
    "print(paste0(\"Intervalle de Confiance: \",  p_hat + q *sqrt(sigma2_p/nb_realisations),  \" \",  p_hat - q *sqrt(sigma2_p/nb_realisations)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " On constate ainsi que notre estimation de $p$ vaut 0. Cela signifie que sur 10 000 réalisations de l'exponentielle, \n",
    "aucune n'est supérieure à t. Cela montre bien qu'il s'agit d'un évènement rare et que la méthode de Monte Carlo Classique n'est pas appropriée.\n",
    "\n",
    "On essaie un nouvel estimateur selon la méthode de Monte Carlo classique :\n",
    "\n",
    "On génère m échantillons  de taille n  de loi exponentielle et on retient le maximum de chaque échantillon :\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{p} = \\displaystyle\\sum_{i=1}^{m} \\mathbb{1}_{\\max(V_{1}...V_{n})>t}\n",
    "\\end{equation}\n",
    "\n",
    "On calcule l'intervalle de confinance asymptotique\n",
    "\n",
    "\n",
    "$\\mathrm{IC}_{1-\\alpha}=\\left[\\hat{p}_{n}-q_{1-\\alpha / 2} \\sqrt{\\frac{\\sigma^{2}}{n}}, \\hat{p}_{n}+q_{1-\\alpha / 2} \\sqrt{\\frac{\\sigma^{2}}{n}}\\right] \\quad$ avec $\\quad \\Phi\\left(q_{1-a / 2}\\right)=1-\\frac{\\alpha}{2}$\n",
    "\n",
    "et $\\sigma^{2}$ la variance empirique des réalisations $\\mathbb{1}_{X_{i}>t}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Estimation de p: 1e-04\"\n",
      "[1] \"Variance : 1e-04\"\n",
      "[1] \"Intervalle de Confiance: 8.10406758778516e-05 0.000118959324122148\"\n"
     ]
    }
   ],
   "source": [
    "# monte carlo classique 2e méthode\n",
    "\n",
    "estim_rare_classique2 = function(nb_realisations  =  1000, lambda  =  2, t =  8, n  =  1000){\n",
    "    V  =  matrix(rexp(nb_realisations*n, lambda), nrow =nb_realisations )\n",
    "    Vmax = apply(V, MARGIN = 1, max) \n",
    "\n",
    "    indicatrice  =  ifelse(Vmax>t,  1,  0)\n",
    "    p_hat  =  mean(indicatrice)\n",
    "\n",
    "    sigma2_p  =  var(indicatrice) # variance\n",
    "\n",
    "    return (c(p_hat, sigma2_p))\n",
    "\n",
    "}\n",
    "\n",
    "estim_classique = estim_rare_classique2( nb_realisations = 10000 )\n",
    "p_hat = estim_classique[1]\n",
    "sigma2_p  = estim_classique[2]\n",
    "\n",
    "print(paste0(\"Estimation de p: \", p_hat))\n",
    "print(paste0(\"Variance : \", sigma2_p))\n",
    "q  =  qnorm(0.975)\n",
    "print(paste0(\"Intervalle de Confiance: \",  p_hat - q *sqrt(sigma2_p/nb_realisations),  \" \",  p_hat + q *sqrt(sigma2_p/nb_realisations)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: \n",
    "\n",
    "### a) Montrer que V(n) −0.5log(n) converge en loi vers une loi de Gumbel dont on précisera les paramètres\n",
    "\n",
    "Soit $a$ un réel,\n",
    "\n",
    "\\begin{align}\n",
    " F_{V_{n}-0.5\\log(n)} (a)  &=  \\mathbb{P} (V_{n}-0.5\\log(n) \t\\leq a)   \\\\\n",
    "                            &= F_{V_{n}} (a + 0.5\\log(n))  \\\\\n",
    "                            &= \\displaystyle(1- e^{-2(a + 0.5\\log(n)) })^{n}   \\\\\n",
    "  \\lim\\limits_{n\\to\\infty} F_{V_{n}-0.5\\log(n)} (a) &= \\lim\\limits_{n\\to\\infty} (1- e^{-2(a + 0.5log(n)) })^{n} \\\\\n",
    "                            &= \\lim\\limits_{n\\to\\infty} (1- n^{-1}e^{-2a})^{n} \\\\\n",
    "                            &= \\lim\\limits_{n\\to\\infty} e^{n\\log(1- n^{-1}e^{-2a})} \n",
    "\\end{align}\n",
    "\n",
    "Or $ \\log(1- n^{-1}e^{-2a}) \\sim_{n\\to\\infty} (\\frac{-e^{-2a}} {n}) $\n",
    "\n",
    "Ainsi \n",
    "\\begin{align}\n",
    " \\lim\\limits_{n\\to\\infty} F_{V_{n}-0.5\\log(n)} (a) &=\\lim\\limits_{n\\to\\infty} e^{- e^{-2a}}\\\\\n",
    "                                                   &= \\exp(-\\exp(-2a)) \n",
    "\\end{align}\n",
    "\n",
    "Donc $V(n) −0.5log(n)$ converge bien en loi vers une Gumbel de paramètre $\\mu = 0$ et $\\beta = 1/2$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) En déduire une estimation de p par la méthode d’échantillonage préférentiel avec un intervalle de confiance au niveau 95%. Vous justifierez le choix de la loi d’importance.\n",
    "On sait que \n",
    "\n",
    "\\begin{align}\n",
    "p  &= \\displaystyle\\int_{t}^{\\infty} n\\lambda e^{-\\lambda x}(1-e^{-\\lambda x })^{n-1} dx \\\\\n",
    "   &= \\displaystyle\\int_{t}^{\\infty} n\\lambda e^{-\\lambda x}(1-e^{-\\lambda x })^{n-1} \\frac{g(x)}{g(x)}dx\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "L'estimateur par la méthode d’échantillonage préférentiel  est donné par \n",
    "\\begin{equation}\n",
    "\\widehat{p} = \\displaystyle\\sum_{i=1}^{n} \\frac{(1-e^{-\\lambda X_{i} })^{n-1} \\mathbb{1}_{X_{i}>0}\\mathbb{1}_{X_{i}>t}}{g(X_{i})}\n",
    "\\end{equation}\n",
    "\n",
    "On choisit comme loi d'importance $g$ la Gumbel de paramètre $\\mu = a$ et $\\beta = 1/2$.\n",
    "En effet le support de $g$ inclut celui de $f$. De plus pour tout $x$ positif\n",
    "\n",
    "\\begin{align}\n",
    "\\displaystyle\\frac {f}{g} &= \\displaystyle\\frac {2n e^{-2 x}(1-e^{-2 x })^{n-1} }{2 \\exp \\left\\{-\\exp \\left(-2(x-a))\\right)\\right\\} e^{ \\left(-2(x-a))\\right)}} \\\\\n",
    " &= \\displaystyle\\frac {n(1-e^{-2 x })^{n-1} }{e^{2a}e^{ -e^{2a}e^{ (-2x)}} }\n",
    "\\end{align}\n",
    "On pose $X = e^{-2 x }$, on obtient\n",
    "\n",
    "\\begin{equation}\n",
    "\\displaystyle\\frac {f}{g} = \\displaystyle\\frac {n(1-X)^{n-1} }{e^{2a}e^{ -e^{2a}X} }\n",
    "\\end{equation}\n",
    "Cette fonction est continue sur le compact $[0,1] $ elle est donc bornée, ce qui garantit que la variance de notre estimateur préférentiel \n",
    "$\\operatorname{Var}_{g}\\left[\\widehat{p}(g)\\right]=\\frac{1}{n}\\left\\{\\mathbb{E}_{g}\\left[\\frac{h^{2}(\\boldsymbol{Z}) f^{2}(\\mathbf{Z})}{g^{2}(\\mathbf{Z})}\\right]-p^{2}\\right\\}$\n",
    "est finie \n",
    "\n",
    "Aussi on veut que  $\\mathbb{P}_{g}(X >t)$ soit élevée, de telle sorte que l'évènement d'interêt ne soit plus rare , donc on choisit $a \\geq 8$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Probabilité selon g de l'évènement X>t 0.632120558828558\"\n",
      "[1] \"Probabilité selon f de l'évènement X>t 0.000112528849220528\"\n"
     ]
    }
   ],
   "source": [
    "# Calcul de P(X >t) selon la loi d'importance g\n",
    "n = 1000\n",
    "lambda = 2\n",
    "a=8\n",
    "b= 0.5\n",
    "\n",
    "print(paste0(\"Probabilité selon g de l'évènement X>t \", 1-pgumbel(8, a, b)))\n",
    "\n",
    "print(paste0(\"Probabilité selon f de l'évènement X>t \", 1-pexp(8, lambda)^n))\n",
    "\n",
    "# On obtient une probabilité élevée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise ici une version modifiée de l' effective sample size (ess):\n",
    "\n",
    "\n",
    "$E S S=\\frac{\\left(\\sum_{k=1}^{n} w_{k}\\right)^{2}}{\\sum_{k=1}^{n} w_{k}^{2}}=n \\frac{\\bar{w}_{n}^{2}}{w_{n}^{2}}$\n",
    "\n",
    "Avec\n",
    "\n",
    "${w}_{k}=\\frac{{h(\\mathbf{Z}_{k})f}\\left(\\mathbf{Z}_{k}\\right)}{g\\left({\\boldsymbol{Z}}_{k}\\right)}$\n",
    "\n",
    "\n",
    "et $\\mathbf{Z}_{k}$ des tirages tirages selon la loi d'importance $g$ (Gumbel de parametre $a$\n",
    "\n",
    "Cet ess est different de celui presenté en cours car il inclut la fonction $h$ (ici l'indicatrice $\\mathbb{1}_{Z>t}$ dans le calcul des poids \n",
    "\n",
    "On constate que la valeur de $a$ qui maximise l'ess est $a =t=8$. C'est donc cette valeur qu'on choisit comme paramètre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Ess avec mu = a= 7 : 124.788311692808\"\n",
      "[1] \"Ess avec mu = a= 8 : 565.988354344737\"\n",
      "[1] \"Ess avec mu = a= 9 : 61.160162868717\"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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",
      "text/plain": [
       "Plot with title \"effective sampling size modifié en fonction du parametre mu de la Gumbel\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Effective sample size\n",
    "ess_gumbel = function(a = 8, nb_realisations = 1000,  b = 0.5,  n = 1000, lambda = 2){\n",
    "  t=8\n",
    "  x = simGumbel(nb_realisations, a, b)\n",
    "  indicatrice  =  ifelse(x>t,  1,  0)\n",
    "  w = sum(dexp(x,  lambda)*n*pexp(x, lambda)^(n-1)*indicatrice/dgumbel(x,  a, b))\n",
    "  w1 = sum((dexp(x,  lambda)*n*pexp(x, lambda)^(n-1)*indicatrice/dgumbel(x,  a, b))^{2})\n",
    "  return(w^{2}/w1)\n",
    "}\n",
    "\n",
    "\n",
    "print(paste0(\"Ess avec mu = a= 7 : \", ess_gumbel(a = 7)))\n",
    "\n",
    "print(paste0(\"Ess avec mu = a= 8 : \", ess_gumbel(a = 8)))\n",
    "      \n",
    "print(paste0(\"Ess avec mu = a= 9 : \", ess_gumbel(a = 9)))\n",
    "a = seq (3, 20, 0.1)\n",
    "plot(a, sapply(a,ess_gumbel ), type = \"l\", main = \"effective sampling size modifié en fonction du parametre mu de la Gumbel\", \n",
    "     xlab = \"mu\", ylab = \"ess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On  effectue l'estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Estimation de p : 0.000110835255061891\"\n",
      "[1] \"Variance 8.39873139720754e-09\"\n",
      "[1] \" Intervalle de Confiance: 0.000105155168723776 0.000116515341400006\"\n"
     ]
    }
   ],
   "source": [
    "# Importance Sampling\n",
    "\n",
    "importance_sampling = function(nb_realisations  =  1000, lambda  =  2, a =  8, b  = 0.5, t = 8){\n",
    "\n",
    "    \n",
    "    x  = simGumbel(nb_realisations, a, b)\n",
    "    indicatrice  =  ifelse(x>t,  1,  0)\n",
    "    \n",
    "    # Calcul des hf/g\n",
    "    integrande =  dexp(x,  lambda)*n*pexp(x, lambda)^(n-1)*indicatrice/dgumbel(x,  a, b)\n",
    "    \n",
    "    \n",
    "    p_hat2  =  mean(integrande)\n",
    "    sigma2_p = var(integrande)\n",
    "    return (c(p_hat2,sigma2_p))\n",
    "}\n",
    "\n",
    "is = importance_sampling( a= 8)\n",
    "p_is = is[1]\n",
    "sigma2_is =  is[2]\n",
    "\n",
    "print(paste0(\"Estimation de p : \", p_is))\n",
    "\n",
    "print(paste0(\"Variance \", sigma2_is))\n",
    "\n",
    "nb_realisations = 1000\n",
    "q = qnorm(0.975)\n",
    "print(paste0(\" Intervalle de Confiance: \",  p_is - q *sqrt(sigma2_is/nb_realisations),  \" \", \n",
    "             p_is + q *sqrt(sigma2_is/nb_realisations)   ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 Efficacité relative\n",
    "\n",
    "La méthode d'échantillonage préférentiel est plus de 800 000 fois plus efficace que la méthode de Monte Carlo classsique car elle permet de réduire de maniere importante la variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \" Efficacité relative   885186.691329297\"\n",
      "[1] \" Variance monte carlo classique   0.0001099899989999\"\n",
      "[1] \" Variance importance_sampling   9.08362854427993e-09\"\n"
     ]
    }
   ],
   "source": [
    "# Efficacité relative\n",
    "nb_fois = 10\n",
    "\n",
    "time1 = mean(microbenchmark(estim_rare_classique2() , times =nb_fois)$time)\n",
    "\n",
    "var1 = mean(sapply(rep(10000, nb_fois), estim_rare_classique2) [2,])\n",
    "\n",
    "time2 = mean(microbenchmark(importance_sampling() , times =nb_fois)$time)\n",
    "\n",
    "var2 = mean(sapply(rep(10000, nb_fois), importance_sampling) [2,])\n",
    "\n",
    "\n",
    "eff = time1*var1/(time2*var2)\n",
    "\n",
    "print(paste0(\" Efficacité relative   \" , eff))\n",
    "\n",
    "print(paste0(\" Variance monte carlo classique   \" , var1))\n",
    "\n",
    "print(paste0(\" Variance importance_sampling   \" , var2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. (a) Partant de l’estimateur d’échantillonage préférentiel, construire un nouvel estimateur de p à l’aide de la méthode de la variable antithétique.\n",
    "\n",
    "\n",
    "Notre variable antithétique est définie par:\n",
    "\n",
    "$A(X) = G^{-1}(1-G(X))$\n",
    "\n",
    "avec X simulée selon $g$ , la loi d'importance et $G$ sa fonction de répartition\n",
    "\n",
    "En effet , on sait que $G$ (loi gumbel)  admet une fonction reciproque $G^{-1}$\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbb{P}(A(X) < a) &= \\mathbb{P}(G^{-1}(1-G(X)) <a) \\\\\n",
    "                     &= \\mathbb{P}((G(X) >-G(a)+1) \\\\\n",
    "                     &= \\mathbb{P}((X >G^{-1}(-G(a)+1)) \\\\\n",
    "                     &= 1-G(G^{-1}(-G(a)+1)) \\\\\n",
    "                     &= 1-(-G(a)+1)) \\\\\n",
    "                     &= G(a)\n",
    "\\end{align}\n",
    "\n",
    "Donc $A(X)$ et $X$ suivent la même loi.\n",
    "De plus $A(X)$ et $X$ ont des monotonies opposées\n",
    "\n",
    "L'estimateur est défini par\n",
    "\\begin{align}\n",
    "\\widehat{p}_{n}=\\frac{1}{n} \\sum_{k=1}^{n} \\frac{H\\left(\\mathbf{X}_{k}\\right)+H \\circ A\\left(\\mathbf{X}_{k}\\right)}{2}\n",
    "\\end{align}\n",
    "\n",
    "avec la fonction  $H = \\displaystyle\\frac{hf}{g}$\n",
    "\n",
    "La variance des réalisations est  \n",
    "\n",
    "$\\sigma_{1}^{2}=\\operatorname{Var}[0.5\\{H(\\mathbf{X})+H \\circ A(\\mathbf{X})\\}]$ \n",
    "\n",
    "estimée par  $\\widehat{\\sigma}_{1}^{2}=\\frac{1}{n-1} \\sum_{k=1}^{n}\\left(0.5\\left\\{H\\left(\\mathbf{X}_{k}\\right)+H \\circ A\\left(\\mathbf{X}_{k}\\right)\\right\\}-\\widehat{p}_{n}\\right)^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Estimation de p : 0.000114868980750459\"\n",
      "[1] \"Variance 5.25568452766805e-09\"\n",
      "[1] \" Intervalle de Confiance: 0.000110375708480988 0.00011936225301993\"\n"
     ]
    }
   ],
   "source": [
    "# Antithétique\n",
    "\n",
    "\n",
    "\n",
    "var_estim_antithetique = function(nb_realisations  =  1000, lambda  =  2, a =  8, b  = 0.5, t = 8){\n",
    "\n",
    "    \n",
    "    x  = simGumbel(nb_realisations, a, b)\n",
    "    A_x  =  -b*log(-log((1-pgumbel(x, a, b))))+a # Variable antithetique\n",
    "  \n",
    "    indicatrice  =  ifelse(x>t,  1,  0)\n",
    "    indicatrice2  =  ifelse(A_x>t,  1,  0)\n",
    "    \n",
    "    #H(X)\n",
    "    integrande =  dexp(x,  lambda)*n*pexp(x, lambda)^(n-1)*indicatrice/dgumbel(x,  a, b)\n",
    "    #H(A(X))\n",
    "    integrande2 =  dexp(A_x,  lambda)*n*pexp(A_x, lambda)^(n-1)*indicatrice2/dgumbel(A_x,  a, b) \n",
    "    \n",
    "    \n",
    "    h = 0.5*(integrande + integrande2)\n",
    "    p_hat2  =  mean(h)\n",
    "    sigma2_p = var(h)\n",
    "    return (c(p_hat2,sigma2_p))\n",
    "}\n",
    "\n",
    "nb_realisations = 1000\n",
    "\n",
    "estim_anti = var_estim_antithetique()\n",
    "p_hat = estim_anti[1]\n",
    "sigma_2 = estim_anti[2]\n",
    "\n",
    "print(paste0(\"Estimation de p : \", p_hat))\n",
    "\n",
    "print(paste0(\"Variance \", sigma_2))\n",
    "\n",
    "\n",
    "q = qnorm(0.975)\n",
    "print(paste0(\" Intervalle de Confiance: \",  p_hat - q *sqrt(sigma_2/nb_realisations),  \" \", \n",
    "             p_hat + q *sqrt(sigma_2/nb_realisations)   ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Que pouvez-vous dire de l’efficacité relative de cet estimateur par rapport à l’estimateur d’échantillonage préférentiel ? Si cette modification de l’estimateur permet de réduire la variance de la méthode d’estimation, expliquer pourquoi.\n",
    "\n",
    "L’estimateur d’échantillonage préférentiel est presque 2 fois moins efficace que celui selon la méthode de la variable antithétique (appliquée a l'échantillonage préférentiel) . Cela vient du fait que cette méthode  réduit  la variance de moitié.\n",
    "\n",
    "On peut constater qu'il n'y a quasiment pas de corrélation entre $H(X)$ et $H(A(X))$ , ce qui explique que la variable antithétique appliquée a l'échantillonage préférentiel  soit équivalente a l'échantillonage préférentiel (classique) avec deux fois plus de tirages. Aussi , cela montre que le coût d'évaluation de $H(A(X))$ est faible devant le coût de simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"La Corrélation entre H(X) et H(A(X)) = -0.0116304957700412\"\n"
     ]
    }
   ],
   "source": [
    "# Corrélation entre H(X) et H(A(X))\n",
    "\n",
    "a=1\n",
    "b=2\n",
    "nb_realisations =1000\n",
    "lambda =2\n",
    "n =1000\n",
    "t = 8\n",
    "x  =  simGumbel(nb_realisations,  a, b)\n",
    "A_x  =  -b*log(-log((1-pgumbel(x, a, b))))+a # Variable antithetique\n",
    "indicatrice1  =  ifelse(x>t,  1,  0)\n",
    "indicatrice2  =  ifelse(A_x>t,  1,  0)\n",
    "  \n",
    "  \n",
    "integrande1 =  dexp(x,  lambda)*n*pexp(x, lambda)^(n-1)*indicatrice1/dgumbel(x,  a, b) #H(X)\n",
    "integrande2 =  dexp(A_x,  lambda)*n*pexp(A_x, lambda)^(n-1)*indicatrice2/dgumbel(A_x,  a, b) # H(A(X))\n",
    "\n",
    "print(paste0(\"La Corrélation entre H(X) et H(A(X)) = \", cor(integrande1, integrande2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \" Efficacité relative   1.5261120620283\"\n",
      "[1] \" Variance importance_sampling   9.12844248041776e-09\"\n",
      "[1] \" Variance antithetique 5.06245539602812e-09\"\n"
     ]
    }
   ],
   "source": [
    "# Efficacité relative importance_sampling / antithetique\n",
    "nb_fois = 100\n",
    "\n",
    "time1 = mean(microbenchmark(importance_sampling() , times =nb_fois)$time)\n",
    "\n",
    "var1 = mean(sapply(rep(1000, nb_fois),importance_sampling ) [2,])\n",
    "\n",
    "time2 = mean(microbenchmark(var_estim_antithetique() , times =nb_fois)$time)\n",
    "\n",
    "var2 = mean(sapply(rep(1000, nb_fois), var_estim_antithetique) [2,])\n",
    "\n",
    "\n",
    "eff = time1*var1/(time2*var2)\n",
    "\n",
    "print(paste0(\" Efficacité relative   \" , eff))\n",
    "\n",
    "print(paste0(\" Variance importance_sampling   \" , var1))\n",
    "\n",
    "print(paste0(\" Variance antithetique \" , var2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 ; Donner une estimation de p par la méthode de Monte Carlo classique. On donnera l’intervalle de confiance au niveau 95%\n",
    "\n",
    "$p = \\mathbb{P} (X<3)$\n",
    "\n",
    "Avec $X=\\left\\{\\begin{array}{ll}{0} & {, \\text { si } S=0} \\\\ {\\sum_{s=1}^{S} Q_{s}} & {, \\text { sinon. }}\\end{array}\\right.$ \n",
    "\n",
    "\n",
    "Ainsi l'estimateur selon la méthode de  monte carlo classique est \n",
    "\n",
    "$\\widehat{p} = \\displaystyle\\sum_{i=1}^{n} \\mathbb{1}_{(\\sum_{k=1}^{S_{i}} Q_{k} \\mathbb{1}_{S>0} )<3}$\n",
    "\n",
    "Avec $S_{i}$ simulés selon une poisson de paramètre $\\lambda = 3.7$ et $Q_{k}$ selon une  Weibull de  paramètre de forme $k = 0.5$ et de paramètre d’échelle $\\lambda = 2$.\n",
    "\n",
    "Pour chaque réalisation de $X$ , on simule $S$ et ensuite on simule $X|S = \\sum_{k=1}^{S} Q_{k} \\mathbb{1}_{S>0}$, on prend ensuite l'indicatrice $\\mathbb{1}_{X<3}$\n",
    "\n",
    "On calcule l'intervalle de confiance asymptotique : on peut appliquer le TCL car l'indicatrice $\\mathbb{1}_{X<3}$ est intégrable\n",
    "\n",
    "$\\mathbb{P}\\left[\\sqrt{\\frac{n}{\\sigma^{2}}}\\left(\\widehat{p}_{n}-p\\right) \\leq z\\right]_{n \\rightarrow+\\infty}\\longrightarrow\\Phi(z)$\n",
    "\n",
    "On en déduit l’intervalle de confiance bilatéral symétrique au niveau de confiance asymptotique\n",
    "1−α\n",
    "\n",
    "$\\mathrm{IC}_{1-\\alpha}=\\left[\\hat{p}_{n}-q_{1-\\alpha / 2} \\sqrt{\\frac{\\sigma^{2}}{n}}, \\hat{p}_{n}+q_{1-\\alpha / 2} \\sqrt{\\frac{\\sigma^{2}}{n}}\\right] \\quad$ avec $\\quad \\Phi\\left(q_{1-a / 2}\\right)=1-\\frac{\\alpha}{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Estimation de p: 0.247\"\n",
      "[1] \"Variance 0.186177177177177\"\n",
      "[1] \" Intervalle de Confiance: 0.220256926887899 0.273743073112101\"\n"
     ]
    }
   ],
   "source": [
    "# Monte Carlo Classique\n",
    "estim_pluie_classique = function(nb_realisations  =  1000, lambda  =  3.7, k  =  0.5, echelle  =  2  ){     \n",
    "\n",
    "S  =  rpois(nb_realisations, lambda )\n",
    "Q  = lapply(S,  rweibull, shape  =  k, scale =  echelle )\n",
    "x  =  sapply(Q,  sum)\n",
    "\n",
    "indicatrice  =  ifelse(x<3,  1,  0)\n",
    "\n",
    "p_pluie  =  mean(indicatrice )\n",
    "sigma2_pluie  =  var(indicatrice)\n",
    " \n",
    "return(c(p_pluie, sigma2_pluie))\n",
    "}\n",
    "\n",
    "q =  qnorm(0.975)\n",
    "nb_realisations  =  1000\n",
    "\n",
    "estim_pluie = estim_pluie_classique()\n",
    "\n",
    "p_pluie = estim_pluie[1]\n",
    "sigma2_pluie =  estim_pluie[2]\n",
    "\n",
    "print(paste0(\"Estimation de p: \", p_pluie))\n",
    "\n",
    "print(paste0(\"Variance \", sigma2_pluie))\n",
    "print(paste0(\" Intervalle de Confiance: \",  p_pluie - q *sqrt(sigma2_pluie/nb_realisations),  \" \", \n",
    "             p_pluie + q *sqrt(sigma2_pluie/nb_realisations)   ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. (a) Donner une estimation de p par la méthode de stratification avec allocation proportionnelle, en précisant les strates utilisées. On donnera l’intervalle de confiance au niveau 95%.\n",
    "\n",
    "\n",
    "Il est naturel de choisir comme  variable de stratification $S$  puisque on peut facilement simuler \n",
    "$X|S=k$ (on le fait déjà dans le cadre de la méthode de monte carlo classique) . $S$  a pour support $\\mathbb{N}$ Donc  la partition la plus fine pour $S$ est l'ensemble des évenements ${S=k}$  avec $k$ qui parcourt $\\mathbb{N}$. Mais comme cette partition est infinie, on choisit de s'arrêter au bout d'un certain $K$ et de prendre comme dernière strate $\\{S>K\\}$ en définissant la partition $P$ suivante:\n",
    "\n",
    "$P = \\{\\{S=k\\} \\text{tel que } k<K \\} \\cup \\{\\{S>K\\}\\}$ , $k$ et $K$ entiers positifs.\n",
    "\n",
    "Il suffit de prendre  $K$ grand et tel que $n\\mathbb{P}(S<K)  \\geq 1$  de telle sorte que lors de l'allocation proportionelle on ait au moins une réalisation allouée à cette dernière strate.\n",
    "\n",
    "Selon la méthode d'allocation proportionelle, on alloue $n_{k} = np_{k}$  réalisations de la variable   $X|S=k$ a la strate $D_{k}$, $n$ étant le nombre de réalisations total et $p_{k} = \\mathbb{P} (D_{k})$ pour tout évènement $D_{k}$ appartenant a la partition $P$\n",
    "\n",
    "L'estimateur  est alors $\\widehat{p}_{n}\\left(n_{1}, \\ldots, n_{K}\\right)=\\sum_{k=1}^{K} \\frac{\\mathbb{P}\\left[\\mathbf{S} =k\\right]}{n_{k}} \\sum_{i=1}^{n_{k}} h\\left(\\mathbf{X}| S=k\\right) + \\frac{\\mathbb{P}\\left[\\mathbf{S} >K\\right]}{n_{K}}\\sum_{i=1}^{n_{K}} h\\left(\\mathbf{X}| S>K\\right)$\n",
    "\n",
    "avec $h(X) = \\mathbb{1}_ {X>3}$\n",
    "\n",
    "La variance des evaluations (dont notre estimateur est la moyenne) est estimée comme suit \n",
    "\n",
    "$\\hat{\\sigma}_{n}^{2}\\left(q_{1}, \\ldots, q_{K}\\right)=\\sum_{k=1}^{K} \\frac{p_{k}^{2}}{q_{k}} \\frac{1}{n_{k}-1} \\sum_{i=1}^{n_{k}}\\left\\{h\\left(\\mathbf{x}_{i}^{(k)}\\right)-\\frac{1}{n_{k}} \\sum_{j=1}^{n_{k}} h\\left(\\mathbf{x}_{j}^{(k)}\\right)\\right\\}^{2}$\n",
    "\n",
    "avec  $q_{K} = \\frac{n_{k}}{n}$ et $n$ le nombre de réalisations total\n",
    "\n",
    "avec $\\mathbf{x}^{(k)}$ la variable aleatoire $X|D_{k}$ , pour tout évènement $D_{k}$ appartenant a la partition $P$\n",
    "\n",
    "On retourne un Intervalle de confiance asymptotique\n",
    "\n",
    "$\\mathrm{IC}_{1-\\alpha}=\\left[\\widehat{p}_{n}-q_{1-\\alpha / 2} \\frac{\\widehat{\\sigma}\\left(q_{1}, \\ldots, q_{K}\\right)}{\\sqrt{n}}, \\hat{p}_{n}+q_{1-\\alpha / 2} \\frac{\\widehat{\\sigma}\\left(q_{1}, \\ldots, q_{K}\\right)}{\\sqrt{n}}\\right]$\n",
    "\n",
    "\n",
    "Pour 1000 réalisations on doit choisir {S>10} comme dernière strate :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Allocation pour la strate S>11  0.00136461515964914\"\n",
      "[1] \"Allocation pour la  strate S>10 1.57218100091772\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Si on choisit {S>11} comme dernière strate, \n",
    "#on n'aura pas d'allocation pour la derniere strate pour 1000 réalisations\n",
    "last_strate = 11\n",
    "nb_realisations = 1000 \n",
    "print(paste0(\"Allocation pour la strate S>11  \", (1-ppois(last_strate,lambda))* nb_realisations) )#on vérifie qu'on a au moins une  réalisation allouée à cette dernière strate\n",
    "\n",
    "\n",
    "# Donc On choisit {S>10} comme dernière strate \n",
    "last_strate = 10\n",
    "lambda = 3.7\n",
    "nb_realisations = 1000 \n",
    "print(paste0(\"Allocation pour la  strate S>10 \", (1-ppois(last_strate,lambda))* nb_realisations) )#on vérifie qu'on a au moins une  réalisation allouée à cette dernière strate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Estimation de p 0.254121506678833\"\n",
      "[1] \"Variance 0.127702801673394\"\n",
      "[1] \" Intervalle de Confiance: 0.231972803468134 0.276270209889532\"\n"
     ]
    }
   ],
   "source": [
    "# Estimateur stratifie allocation proportionelle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "estim_strat_prop= function(nb_realisations  =  1000, lambda  =  3.7, k  =  0.5, \n",
    "                                 echelle  =  2, last_strate = 10  ){\n",
    "\n",
    "\n",
    "\n",
    "    p= c(dpois(0:last_strate,lambda), 1-ppois(last_strate,lambda)) # probabilites des strates\n",
    "    n = round(p*nb_realisations) # alllocation proportionelle\n",
    "\n",
    "\n",
    "    strates = list()\n",
    "    for (i in 0:(length(p)-2)){ # Pour chaque strate on obtient un vecteur de realisations\n",
    "      x= c()\n",
    "      for (j in 1:n[i+1]){\n",
    "          \n",
    "        \n",
    "        x =append(x,sum(rweibull(i, k , echelle)) ) \n",
    "        h = ifelse(x<3, 1, 0) #indicatrice\n",
    "\n",
    "      }\n",
    "      strates [[i+1]] = h\n",
    "    }\n",
    "\n",
    "    # pour la derniere strate on utilise une poisson tronquee \n",
    "\n",
    "    S= rtpois(n[length(n)], lambda, a = last_strate)\n",
    "    Q =lapply(S, rweibull,shape = k,scale= echelle )\n",
    "    x = sapply(Q, sum)\n",
    "\n",
    "    strates[[length(p)]] =  ifelse(x<3, 1, 0)\n",
    "\n",
    "    p_strat_prop = sum(p*sapply(strates, mean))\n",
    "    sigma_strat_prop =  sum((sapply(strates, var)*p^2)/(n/sum(n))) # Variance\n",
    "    return(c(p_strat_prop,sigma_strat_prop ))\n",
    "\n",
    " }\n",
    "\n",
    "estim = estim_strat_prop()\n",
    "\n",
    "p_strat_prop = estim[1]\n",
    "sigma_strat_prop =  estim[2]\n",
    "\n",
    "print(paste0(\"Estimation de p \", p_strat_prop))\n",
    "\n",
    "\n",
    "print(paste0(\"Variance \", sigma_strat_prop))\n",
    "\n",
    "q =  qnorm(0.975)\n",
    "nb_realisations  =  1000\n",
    "\n",
    "print(paste0(\" Intervalle de Confiance: \",  p_strat_prop - q *sqrt(sigma_strat_prop/nb_realisations),  \" \",  \n",
    "             p_strat_prop + q *sqrt(sigma_strat_prop/nb_realisations)   ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2   (b) Comparer les variances et l’efficacité relative des deux méthodes d’estimations. Discuter de façon concise les résultats obtenus.\n",
    "\n",
    "\n",
    "On constate que la méthode de stratification avec allocation proportionelle est 3 fois moins efficace que la méthode de monte carlo classique, même si elle permet de réduire légèrement la variance. Ceci vient de l'implémentation de la méthode de stratification : elle utilise des boucles $\\text{for}$ tandis que la méthode de monte carlo classique utilise la vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \" Efficacité relative   3.36791313531709\"\n",
      "[1] \" Variance strates proportionelles   0.13874316830267\"\n",
      "[1] \" Variance monte carlo classique   0.193891281281281\"\n"
     ]
    }
   ],
   "source": [
    "# Efficacité relative\n",
    "nb_fois = 100\n",
    "\n",
    "time1 = mean(microbenchmark(estim_strat_prop() , times =nb_fois)$time)\n",
    "\n",
    "var1 = mean(sapply(rep(1000, nb_fois), estim_strat_prop) [2,])\n",
    "\n",
    "time2 = mean(microbenchmark(estim_pluie_classique() , times =nb_fois)$time)\n",
    "\n",
    "var2 = mean(sapply(rep(1000, nb_fois), estim_pluie_classique) [2,])\n",
    "\n",
    "\n",
    "eff = time1*var1/(time2*var2)\n",
    "\n",
    "print(paste0(\" Efficacité relative   \" , eff))\n",
    "\n",
    "print(paste0(\" Variance strates proportionelles   \" , var1))\n",
    "\n",
    "print(paste0(\" Variance monte carlo classique   \" , var2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 a) Proposer une méthode d’estimation de p par la méthode de stratification avec allocation optimale. Quelles difficultés rencontrez-vous ?\n",
    "\n",
    "\n",
    "On définit notre estimateur comme précedemment\n",
    "\n",
    "$\\widehat{p}_{n}\\left(n_{1}, \\ldots, n_{K}\\right)=\\sum_{k=1}^{K} \\frac{\\mathbb{P}\\left[\\mathbf{S} =k\\right]}{n_{k}} \\sum_{i=1}^{n_{k}} h\\left(\\mathbf{X}| S=k\\right) + \\frac{\\mathbb{P}\\left[\\mathbf{S} >K\\right]}{n_{K}}\\sum_{i=1}^{n_{K}} h\\left(\\mathbf{X}| S>K\\right)$\n",
    "\n",
    "\n",
    "avec les mêmes strates.\n",
    "\n",
    "Cette fois-ci, les allocations sont données par\n",
    "\n",
    "$q_{k}^{\\star}=\\frac{p_{k} \\sigma_{k}}{\\sum_{i=1}^{K} p_{i} \\sigma_{i}}$\n",
    "\n",
    "La difficulté ici est que $\\sigma_{k}$ st inconnue et difficile a calculer.\n",
    "On remplace $\\sigma_{k}$ par son estimateur $\\widehat{\\sigma_{k}}$ défini précedemment et calculé sur un autre échantillon avec une allocation  uniforme (même nombre de  tirages pour chaque strate).\n",
    "\n",
    "Si $q_{k} = 0$ pour une strate $D_{k}$, on lui alloue 2 tirages pour que notre estimateur reste sans biais. (on force 2 tirages plutot que un parce que l'estimateur de la variance n'est pas défini pour des échantillons de taile 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Estimation de p 0.268726114447987\"\n",
      "[1] \"Variance 0.137558299496803\"\n",
      "[1] \" Intervalle de Confiance Asymptotique: 0.245738627787596 0.291713601108379\"\n"
     ]
    }
   ],
   "source": [
    "### Allocation optimale #####\n",
    "\n",
    "estim_strat_opti = function( nb_realisations  =  1000, lambda  =  3.7, k  =  0.5, \n",
    "                                 echelle  =  2, last_strate = 10) {\n",
    "\n",
    "    # Calcul des allocations (on estime les variances intra strates)\n",
    "    \n",
    "    last_strate =10\n",
    "    p =  c(dpois(0:last_strate, lambda),  1-ppois(last_strate, lambda)) # probabilites des strates\n",
    "    n  =  rep(nb_realisations/10,  length(p)) # alllocation uniforme\n",
    "\n",
    "    \n",
    "\n",
    "    strates  =  list()\n",
    "    for (i in 0:(length(p)-2)){ # Pour chaque strate on obtient un vecteur de realisations\n",
    "      x =  c()\n",
    "      for (j in 1:n[i+1]){\n",
    "\n",
    "        x  = append(x, sum(rweibull(i,  k ,  echelle)) ) \n",
    "        h  =  ifelse(x>3,  1,  0)\n",
    "\n",
    "      }\n",
    "      strates [[i+1]]  =  h\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    S =  rtpois(n[length(n)],  lambda,  a  =  last_strate)\n",
    "    Q  = lapply(S,  rweibull, shape  =  k, scale =  echelle )\n",
    "    x  =  sapply(Q,  sum)\n",
    "\n",
    "    strates[[length(p)]]  =   ifelse(x>3,  1,  0)\n",
    "\n",
    "\n",
    "\n",
    "    var_strates  =   sapply(strates,  var)\n",
    "\n",
    "    q_k  =  p*sqrt( var_strates)/sum(p*sqrt( var_strates))\n",
    "\n",
    "    ## estimation\n",
    "\n",
    "    \n",
    "    p =  c(dpois(0:last_strate, lambda),  1-ppois(last_strate, lambda)) # probabilites des strates\n",
    "    n  =  round(q_k*nb_realisations) # alllocation optimale\n",
    "\n",
    "    # On force des tirages pour  les strates qui ont une allocation nulle\n",
    "\n",
    "    n[n<2]  =  2\n",
    "\n",
    "    strates  =  list()\n",
    "    for (i in 0:(length(p)-2)){ # Pour chaque strate on obtient un vecteur de realisations\n",
    "      x =  c()\n",
    "      for (j in 1:n[i+1]){\n",
    "\n",
    "        x  = append(x, sum(rweibull(i, k , echelle)) ) \n",
    "        h  =  ifelse(x<3, 1, 0)\n",
    "\n",
    "      }\n",
    "      strates [[i+1]]  = h\n",
    "    }\n",
    "    \n",
    "    #  derniere strate \n",
    "\n",
    "\n",
    "    S =  rtpois(n[length(n)],  lambda,  a  =  last_strate)\n",
    "    Q  = lapply(S,  rweibull, shape  =  k, scale =  echelle )\n",
    "    x  =  sapply(Q,  sum)\n",
    "\n",
    "    strates[[length(p)]]  =   ifelse(x<3,  1,  0)\n",
    "\n",
    "    p_strat_opt  =  sum(p*sapply(strates, mean))\n",
    "\n",
    "    sigma_strat_opt  =   sum((sapply(strates, var)*p^2)/(n/sum(n)))\n",
    "    return(c(p_strat_opt,sigma_strat_opt ))\n",
    " }\n",
    "\n",
    "estim_opti = estim_strat_opti()\n",
    "p_strat_opt = estim_opti[1]\n",
    "sigma_strat_opt = estim_opti[2]\n",
    "\n",
    "\n",
    "print(paste0(\"Estimation de p \", p_strat_opt))\n",
    "\n",
    "\n",
    "print(paste0(\"Variance \", sigma_strat_opt))\n",
    "\n",
    "q =  qnorm(0.975)\n",
    "nb_realisations  =  1000\n",
    "\n",
    "print(paste0(\" Intervalle de Confiance Asymptotique: \",  p_strat_opt - q *sqrt(sigma_strat_opt/nb_realisations),  \" \",  p_strat_opt + q *sqrt(sigma_strat_opt/nb_realisations)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (b) Comparer les variances et l’efficacité relative de ces trois méthodes d’estimations. Discuter de façon concise les résultats obtenus\n",
    "\n",
    "On constate que la méthodes de stratification avec allocation otpimale est presque 2 fois moins efficace que celle avec allocation proportionelle, même si elle réduit très légèrement la variance. Cela vient du fait que l'allocation optimale nécessite de calculer une estimation des variances sur un autre echantillon et donc prend forcement plus de temps de calcul que l'allocation proportionelle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \" Efficacité relative   2.21361791193946\"\n",
      "[1] \" Variance strates proportionelles   0.128740245656526\"\n",
      "[1] \" Variance allocation otpimale  0.13861401499749\"\n",
      "[1] \" Efficacité relative   6.48746732663944\"\n",
      "[1] \" Variance strates proportionelles   0.126126710792994\"\n",
      "[1] \" Variance monte carlo classique  0.192842502502503\"\n"
     ]
    }
   ],
   "source": [
    "# Efficacité relative allocation proportionelle vs Optimale\n",
    "nb_fois = 100\n",
    "\n",
    "time1 = mean(microbenchmark(estim_strat_opti() , times =nb_fois)$time)\n",
    "\n",
    "var1 = mean(sapply(rep(1000, nb_fois),estim_strat_opti ) [2,])\n",
    "\n",
    "time2 = mean(microbenchmark(estim_strat_prop() , times =nb_fois)$time)\n",
    "\n",
    "var2 = mean(sapply(rep(1000, nb_fois), estim_strat_prop) [2,])\n",
    "\n",
    "\n",
    "eff = time1*var1/(time2*var2)\n",
    "\n",
    "print(paste0(\" Efficacité relative   \" , eff))\n",
    "\n",
    "print(paste0(\" Variance strates proportionelles   \" , var1))\n",
    "\n",
    "print(paste0(\" Variance allocation otpimale  \" , var2))\n",
    "\n",
    "\n",
    "\n",
    "# Efficacité relative Classique vs Optimale\n",
    "nb_fois = 100\n",
    "\n",
    "time1 = mean(microbenchmark(estim_strat_opti() , times =nb_fois)$time)\n",
    "\n",
    "var1 = mean(sapply(rep(1000, nb_fois),estim_strat_opti ) [2,])\n",
    "\n",
    "time2 = mean(microbenchmark(estim_pluie_classique() , times =nb_fois)$time)\n",
    "\n",
    "var2 = mean(sapply(rep(1000, nb_fois), estim_pluie_classique) [2,])\n",
    "\n",
    "\n",
    "eff = time1*var1/(time2*var2)\n",
    "\n",
    "print(paste0(\" Efficacité relative   \" , eff))\n",
    "\n",
    "print(paste0(\" Variance strates proportionelles   \" , var1))\n",
    "\n",
    "print(paste0(\" Variance monte carlo classique  \" , var2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
